{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-da961c847537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_file2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*'"
     ]
    }
   ],
   "source": [
    "data_file=\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/test_W2.txt\"\n",
    "data_file2=\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*\"\n",
    "\n",
    "with open(data_file2, 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(i)\n",
    "        print(line)\n",
    "        print(gensim.utils.simple_preprocess(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 23:14:51,559 : INFO : reading file /mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*...this may take a while\n",
      "2019-09-14 23:14:51,854 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    for file in glob.glob(input_file):\n",
    "        with open(file, 'rb') as f:\n",
    "            for i, line in enumerate (f): \n",
    "            #if (i%10000==0):\n",
    "                #logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "                yield gensim.utils.simple_preprocess (line)\n",
    "            yield [\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\"]\n",
    "            \n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents2 = list (read_input(data_file2))\n",
    "\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bml',\n",
       "  'cpp',\n",
       "  'defines',\n",
       "  'the',\n",
       "  'entry',\n",
       "  'point',\n",
       "  'for',\n",
       "  'the',\n",
       "  'console',\n",
       "  'application'],\n",
       " [],\n",
       " [],\n",
       " ['include', 'stdafx'],\n",
       " ['include', 'iostream'],\n",
       " ['include', 'time'],\n",
       " ['include', 'windows'],\n",
       " ['include', 'math'],\n",
       " ['include', 'cstdlib'],\n",
       " ['using', 'namespace', 'std'],\n",
       " ['int', 'matrixsize'],\n",
       " ['bool', 'ischecked'],\n",
       " ['int', 'probability', 'procentach'],\n",
       " [],\n",
       " ['int', 'main'],\n",
       " [],\n",
       " ['bool', 'checkede', 'false'],\n",
       " ['bool', 'checkedn', 'false'],\n",
       " ['bool', 'tick', 'false'],\n",
       " ['generujemy', 'tablice'],\n",
       " ['int', 'matrix', 'new', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['matrix', 'new', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['generujemy', 'tablice', 'pomocnicza'],\n",
       " ['int', 'matrix', 'new', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['matrix', 'new', 'int', 'matrixsize'],\n",
       " [],\n",
       " [],\n",
       " ['wypelniamy', 'glowna', 'tablice', 'zerami'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " ['wypelniamy', 'macierz', 'pomocnicza', 'zerami'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['int', 'probability', 'floor', 'probability'],\n",
       " [],\n",
       " ['srand', 'time', 'null'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " [],\n",
       " ['generowanie', 'pojazdow'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['cout', 'endl'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " [],\n",
       " [],\n",
       " ['int',\n",
       "  'rand',\n",
       "  'losujemy',\n",
       "  'czy',\n",
       "  'dane',\n",
       "  'pole',\n",
       "  'bedzie',\n",
       "  'puste',\n",
       "  'czy',\n",
       "  'nie'],\n",
       " ['if',\n",
       "  'probability',\n",
       "  'jesli',\n",
       "  'polu',\n",
       "  'ma',\n",
       "  'byc',\n",
       "  'wygenerowany',\n",
       "  'samochod'],\n",
       " [],\n",
       " [],\n",
       " ['int', 'rand', 'losowanie', 'jaki', 'pojazd', 'zostanie', 'przypisany'],\n",
       " ['if',\n",
       "  'jesli',\n",
       "  'to',\n",
       "  'samochod',\n",
       "  'przesuwa',\n",
       "  'sie',\n",
       "  'gore',\n",
       "  'jesli',\n",
       "  'to',\n",
       "  'prawo'],\n",
       " [],\n",
       " ['if', 'matrix', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " ['if', 'jesli', 'to', 'samochod', 'przesuwa', 'sie', 'prawo'],\n",
       " [],\n",
       " ['if', 'matrix', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix', 'puste', 'pole'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['while'],\n",
       " [],\n",
       " ['wyswietlanie', 'samochodow'],\n",
       " ['system', 'cls'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['cout', 'puste', 'pole'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'gore'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'prawo'],\n",
       " [],\n",
       " [],\n",
       " ['cout', 'endl'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['przesuwanie', 'pojazdow'],\n",
       " ['if',\n",
       "  'tick',\n",
       "  'false',\n",
       "  'tym',\n",
       "  'przypadku',\n",
       "  'ruszaja',\n",
       "  'sie',\n",
       "  'samochody',\n",
       "  'idace',\n",
       "  'prawo'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['int'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['if',\n",
       "  'tick',\n",
       "  'true',\n",
       "  'tutaj',\n",
       "  'przesuwaja',\n",
       "  'sie',\n",
       "  'samochodu',\n",
       "  'poruszajace',\n",
       "  'sie',\n",
       "  'gore'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['int'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['tick', 'tick'],\n",
       " ['tick',\n",
       "  'tick',\n",
       "  'zmieniamy',\n",
       "  'rodzaj',\n",
       "  'samochodow',\n",
       "  'ktore',\n",
       "  'beda',\n",
       "  'przesuwane',\n",
       "  'nastepnej',\n",
       "  'iteracji'],\n",
       " [],\n",
       " ['test', 'wyswietlania'],\n",
       " ['cout', 'endl'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['cout', 'puste', 'pole'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'gore'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'prawo'],\n",
       " [],\n",
       " [],\n",
       " ['cout', 'endl'],\n",
       " [],\n",
       " ['sleep'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix', 'matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['zerujemy', 'macierz', 'pomocnicza'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['sleep'],\n",
       " [],\n",
       " ['system', 'pause'],\n",
       " ['return'],\n",
       " [],\n",
       " ['using', 'system', 'collections'],\n",
       " ['using', 'system', 'collections', 'generic'],\n",
       " ['using', 'unityengine'],\n",
       " [],\n",
       " ['enum', 'tile', 'plains', 'desert', 'mountain', 'forest'],\n",
       " ['enum', 'resource', 'wood', 'stone', 'fruit'],\n",
       " [],\n",
       " ['public', 'class', 'tilecontroller', 'monobehaviour'],\n",
       " [],\n",
       " ['serializefield'],\n",
       " ['private', 'meshfilter'],\n",
       " ['serializefield'],\n",
       " ['private', 'renderer'],\n",
       " ['private',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'transform',\n",
       "  'new',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'transform'],\n",
       " ['public',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'float',\n",
       "  'maxscales',\n",
       "  'new',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'float'],\n",
       " [],\n",
       " ['public', 'animationcurve', 'resourcecurve'],\n",
       " [],\n",
       " ['public', 'void', 'somefunction', 'resource'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['iferror',\n",
       "  'if',\n",
       "  'or',\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  'found',\n",
       "  'nfound'],\n",
       " [],\n",
       " ['sub'],\n",
       " [],\n",
       " ['dim', 'strsearch', 'as', 'string'],\n",
       " ['dim', 'arysearch', 'as', 'variant'],\n",
       " ['dim', 'searchrng', 'as', 'range'],\n",
       " ['dim', 'cel', 'as', 'range'],\n",
       " ['dim', 'as', 'long', 'ii', 'as', 'long'],\n",
       " [],\n",
       " [],\n",
       " ['set', 'searchrng', 'application', 'selection'],\n",
       " ['strsearch',\n",
       "  'inputbox',\n",
       "  'please',\n",
       "  'enter',\n",
       "  'the',\n",
       "  'text',\n",
       "  'to',\n",
       "  'make',\n",
       "  'bold',\n",
       "  'as',\n",
       "  'comma',\n",
       "  'delimited',\n",
       "  'list',\n",
       "  'abc',\n",
       "  'xyz',\n",
       "  'no',\n",
       "  'spaces',\n",
       "  'bold',\n",
       "  'text'],\n",
       " ['if', 'strsearch', 'then', 'exit', 'sub'],\n",
       " ['arysearch', 'split', 'strsearch'],\n",
       " ['for', 'each', 'cel', 'in', 'searchrng'],\n",
       " [],\n",
       " ['with', 'cel'],\n",
       " [],\n",
       " ['font', 'bold', 'false'],\n",
       " ['for', 'ii', 'lbound', 'arysearch', 'to', 'ubound', 'arysearch'],\n",
       " [],\n",
       " ['instr', 'cel', 'value', 'arysearch', 'ii'],\n",
       " ['if', 'then'],\n",
       " [],\n",
       " ['characters', 'len', 'arysearch', 'ii', 'font', 'bold', 'true'],\n",
       " ['end', 'if'],\n",
       " ['next', 'ii'],\n",
       " ['end', 'with'],\n",
       " ['next', 'cel'],\n",
       " [],\n",
       " ['end', 'sub'],\n",
       " ['documentclass', 'border', 'pt', 'standalone'],\n",
       " ['usepackage', 'makecell'],\n",
       " [],\n",
       " ['cc'],\n",
       " ['begin', 'document'],\n",
       " ['pt', 'makegapedcells'],\n",
       " ['begin', 'tabular', 'rllllll'],\n",
       " ['nline', 'hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " ['end', 'document'],\n",
       " [],\n",
       " ['documentclass', 'article'],\n",
       " [],\n",
       " ['usepackage', 'makecell', 'etoolbox'],\n",
       " [],\n",
       " ['makeatletter'],\n",
       " ['newcommand', 'nheadline'],\n",
       " ['patchcmd', 'nline', 'cmd'],\n",
       " ['num', 'search'],\n",
       " ['theadfontnum', 'replace'],\n",
       " ['success', 'failure'],\n",
       " ['theadfontnline'],\n",
       " [],\n",
       " ['makeatother'],\n",
       " [],\n",
       " ['bfseries'],\n",
       " [],\n",
       " ['begin', 'document'],\n",
       " [],\n",
       " ['begin', 'tabular'],\n",
       " ['nheadline'],\n",
       " ['nline'],\n",
       " ['hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " [],\n",
       " ['end', 'document'],\n",
       " [],\n",
       " ['documentclass', 'article'],\n",
       " [],\n",
       " ['usepackage', 'makecell', 'multido'],\n",
       " [],\n",
       " ['makeatletter'],\n",
       " [],\n",
       " ['newcommand', 'headalign', 'multicolumn'],\n",
       " ['newcommand', 'createheadline'],\n",
       " ['def', 'headline'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['multido'],\n",
       " ['edefx', 'headline', 'headline', 'headalign', 'theadfonti'],\n",
       " [],\n",
       " ['expandafter', 'gobble', 'headline'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['newcommand', 'setheadline', 'headline'],\n",
       " [],\n",
       " ['makeatother'],\n",
       " [],\n",
       " ['bfseries'],\n",
       " [],\n",
       " ['begin', 'document'],\n",
       " [],\n",
       " ['begin', 'tabular'],\n",
       " ['createheadline', 'setheadline'],\n",
       " ['nline'],\n",
       " ['hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " [],\n",
       " ['end', 'document'],\n",
       " ['output',\n",
       "  'kali',\n",
       "  'bryant',\n",
       "  'megfogja',\n",
       "  'es',\n",
       "  'az',\n",
       "  'övére',\n",
       "  'csatolja',\n",
       "  'deasert',\n",
       "  'kaliberü',\n",
       "  'fegyvertz'],\n",
       " ['output', 'az', 'öven', 'van', 'kali', 'bryant'],\n",
       " ['output', 'boris', 'ivanokov', 'mondja', 'miért', 'veszi', 'ki'],\n",
       " ['output',\n",
       "  'kali',\n",
       "  'bryant',\n",
       "  'kivett',\n",
       "  'egy',\n",
       "  'tárgyat',\n",
       "  'jármű',\n",
       "  'desert',\n",
       "  'eagle',\n",
       "  'pisztoly'],\n",
       " ['source', 'code', 'of', 'expert', 'system'],\n",
       " ['go'],\n",
       " ['hypothesis', 'disease'],\n",
       " ['write', 'believe', 'that', 'the', 'patient', 'have'],\n",
       " ['write', 'disease'],\n",
       " ['nl'],\n",
       " ['write', 'take', 'care'],\n",
       " ['undo'],\n",
       " [],\n",
       " ['hypothesis', 'that', 'should', 'be', 'tested'],\n",
       " ['hypothesis', 'cold', 'cold'],\n",
       " ['hypothesis', 'flu', 'flu'],\n",
       " ['hypothesis', 'typhoid', 'typhoid'],\n",
       " ['hypothesis', 'measles', 'measles'],\n",
       " ['hypothesis', 'malaria', 'malaria'],\n",
       " ['hypothesis', 'unknown', 'no', 'diagnosis'],\n",
       " [],\n",
       " ['hypothesis', 'identification', 'rules'],\n",
       " [],\n",
       " ['cold'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'runny_nose'],\n",
       " ['verify', 'sneezing'],\n",
       " ['verify', 'sore_throat'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tylenol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'panadol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'nasal', 'spray'],\n",
       " ['nl'],\n",
       " ['write', 'please', 'weare', 'warm', 'cloths', 'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['flu'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'chills'],\n",
       " ['verify', 'body_ache'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tamiflu', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'panadol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'zanamivir', 'tab'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'take',\n",
       "  'warm',\n",
       "  'bath',\n",
       "  'and',\n",
       "  'do',\n",
       "  'salt',\n",
       "  'gargling',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['typhoid'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'abdominal_pain'],\n",
       " ['verify', 'poor_appetite'],\n",
       " ['verify', 'fever'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'chloramphenicol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'amoxicillin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'ciprofloxacin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'azithromycin', 'tab'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'do',\n",
       "  'complete',\n",
       "  'bed',\n",
       "  'rest',\n",
       "  'and',\n",
       "  'take',\n",
       "  'soft',\n",
       "  'diet',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['measles'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'runny_nose'],\n",
       " ['verify', 'rash'],\n",
       " ['verify', 'conjunctivitis'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tylenol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'aleve', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'advil', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'vitamin'],\n",
       " ['nl'],\n",
       " ['write', 'please', 'get', 'rest', 'and', 'use', 'more', 'liquid', 'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['malaria'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'sweating'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'nausea'],\n",
       " ['verify', 'vomiting'],\n",
       " ['verify', 'diarrhea'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'aralen', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'qualaquin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'plaquenil', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'mefloquine'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'do',\n",
       "  'not',\n",
       "  'sleep',\n",
       "  'in',\n",
       "  'open',\n",
       "  'air',\n",
       "  'and',\n",
       "  'cover',\n",
       "  'your',\n",
       "  'full',\n",
       "  'skin',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['how', 'to', 'ask', 'questions'],\n",
       " ['ask', 'question'],\n",
       " ['write', 'does', 'the', 'patient', 'have', 'following', 'symptom'],\n",
       " ['write', 'question'],\n",
       " ['write'],\n",
       " ['read', 'response'],\n",
       " ['nl'],\n",
       " ['response', 'yes', 'response'],\n",
       " [],\n",
       " ['assert', 'yes', 'question'],\n",
       " ['assert', 'no', 'question', 'fail'],\n",
       " [],\n",
       " ['dynamic', 'yes', 'no'],\n",
       " ['how', 'to', 'verify', 'something'],\n",
       " ['verify'],\n",
       " ['yes'],\n",
       " [],\n",
       " ['true'],\n",
       " ['no'],\n",
       " [],\n",
       " ['fail'],\n",
       " ['ask'],\n",
       " ['undo', 'all', 'yes', 'no', 'assertions'],\n",
       " ['undo', 'retract', 'yes', 'fail'],\n",
       " ['undo', 'retract', 'no', 'fail'],\n",
       " ['undo'],\n",
       " ['class', 'myclass', 'ienumerable', 'int'],\n",
       " [],\n",
       " ['public', 'ienumerator', 'int', 'getenumerator'],\n",
       " [],\n",
       " ['for', 'int'],\n",
       " [],\n",
       " ['yield', 'return'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ienumerator', 'ienumerable', 'getenumerator'],\n",
       " [],\n",
       " ['return', 'ienumerable', 'this', 'getenumerator', 'всё', 'хорошо'],\n",
       " ['return', 'ienumerable', 'this', 'getenumenator', 'error'],\n",
       " [],\n",
       " ['portability', 'of', 'wild', 'pathname'],\n",
       " [],\n",
       " ['on',\n",
       "  'most',\n",
       "  'cl',\n",
       "  'implementations',\n",
       "  'cl',\n",
       "  'parse',\n",
       "  'namestring',\n",
       "  'or',\n",
       "  'interprets',\n",
       "  'unix',\n",
       "  'like',\n",
       "  'pathname',\n",
       "  'including',\n",
       "  'wildcard',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'qux',\n",
       "  'lisp',\n",
       "  'in',\n",
       "  'common',\n",
       "  'way',\n",
       "  'however',\n",
       "  'there',\n",
       "  'are',\n",
       "  'minor',\n",
       "  'differences',\n",
       "  'in',\n",
       "  'behaviour',\n",
       "  'and',\n",
       "  'facility',\n",
       "  'below',\n",
       "  'is',\n",
       "  'table',\n",
       "  'summarizing',\n",
       "  'the',\n",
       "  'points'],\n",
       " [],\n",
       " ['as', 'one', 'directory'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'baz', 'foo', 'baz'],\n",
       " [],\n",
       " ['as', 'zero', 'or', 'more', 'directories'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'baz', 'qux', 'foo', 'qux'],\n",
       " ['pathname', 'match', 'foo', 'qux', 'foo', 'qux'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'baz',\n",
       "  'qux',\n",
       "  'qux',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['as', 'file', 'name', 'or', 'file', 'type'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'lisp', 'foo', 'nil'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo'],\n",
       " ['pathname',\n",
       "  'name',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild'],\n",
       " ['pathname',\n",
       "  'type',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'lisp', 'foo', 'bar'],\n",
       " ['pathname', 'match', 'foo', 'lisp', 'foo'],\n",
       " ['pathname', 'name', 'foo', 'bar', 'obj', 'sup', 'footnote', 'sup', 'nil'],\n",
       " ['pathname',\n",
       "  'type',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'nil',\n",
       "  'wild',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'wild'],\n",
       " [],\n",
       " ['name',\n",
       "  'footnote',\n",
       "  'sbcl',\n",
       "  'provides',\n",
       "  'class',\n",
       "  'sb',\n",
       "  'impl',\n",
       "  'pattern',\n",
       "  'for',\n",
       "  'this',\n",
       "  'purpose',\n",
       "  'which',\n",
       "  'is',\n",
       "  'here',\n",
       "  'virtually',\n",
       "  'equivalent',\n",
       "  'to'],\n",
       " [],\n",
       " ['as', 'part', 'of', 'directory', 'name'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo', 'bar', 'nil'],\n",
       " ['pathname', 'match', 'footprint', 'bar', 'foo', 'bar'],\n",
       " [],\n",
       " ['as', 'part', 'of', 'file', 'name', 'or', 'file', 'type'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'test', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'mjs', 'foo', 'bar', 'js'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'test',\n",
       "  'js',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'js',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['wildcard'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'baz', 'foo', 'baz', 'nil', 'nil', 'nil'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['the', 'version', 'of', 'each', 'implementation', 'is', 'as', 'follows'],\n",
       " [],\n",
       " ['sbcl', 'sbcl', 'win'],\n",
       " ['clozure', 'cl', 'ccl', 'win'],\n",
       " ['clisp', 'clisp', 'win'],\n",
       " ['abcl', 'abcl', 'fasl', 'win'],\n",
       " ['ecl', 'ecl', 'cb', 'win'],\n",
       " ['allegro', 'cl', 'acl', 'win'],\n",
       " ['lispworks', 'lwpe', 'win'],\n",
       " ['parallel', 'for', 'loop'],\n",
       " ['int',\n",
       "  'recordcount',\n",
       "  'lhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'rhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'rhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'lhs',\n",
       "  'listdata',\n",
       "  'count'],\n",
       " [],\n",
       " ['list', 'double', 'listresult', 'new', 'list', 'double', 'recordcount'],\n",
       " ['var', 'partitioner', 'create', 'recordcount'],\n",
       " [],\n",
       " ['parallel', 'foreach', 'range'],\n",
       " [],\n",
       " ['for', 'int', 'index', 'range', 'item', 'index', 'range', 'item', 'index'],\n",
       " [],\n",
       " ['double', 'result', 'lhs', 'listdata', 'index', 'rhs', 'listdata', 'index'],\n",
       " ['listresult', 'add', 'result'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ienumerable',\n",
       "  'double',\n",
       "  'lhs',\n",
       "  'rhs',\n",
       "  'assume',\n",
       "  'these',\n",
       "  'are',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'your',\n",
       "  'numbers'],\n",
       " ['double',\n",
       "  'result',\n",
       "  'system',\n",
       "  'linq',\n",
       "  'enumerable',\n",
       "  'zip',\n",
       "  'lhs',\n",
       "  'rhs',\n",
       "  'asparallel',\n",
       "  'toarray'],\n",
       " [],\n",
       " ['var', 'listresult', 'lhs', 'asparallel'],\n",
       " ['zip', 'rhs', 'asparallel'],\n",
       " ['tolist'],\n",
       " [],\n",
       " ['listresult', 'index', 'result'],\n",
       " ['color', 'ffff', 'hello', 'guys'],\n",
       " ['have',\n",
       "  'an',\n",
       "  'easy',\n",
       "  'autopilot',\n",
       "  'method',\n",
       "  'which',\n",
       "  'will',\n",
       "  'for',\n",
       "  'sure',\n",
       "  'bring',\n",
       "  'you',\n",
       "  'some',\n",
       "  'big',\n",
       "  'money',\n",
       "  'and',\n",
       "  'even',\n",
       "  'more',\n",
       "  'than',\n",
       "  'per',\n",
       "  'day',\n",
       "  'if',\n",
       "  'done',\n",
       "  'right',\n",
       "  'color'],\n",
       " [],\n",
       " ['center',\n",
       "  'img',\n",
       "  'https',\n",
       "  'ibb',\n",
       "  'co',\n",
       "  'rscr',\n",
       "  'screenshot',\n",
       "  'jpg',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'why',\n",
       "  'is',\n",
       "  'this',\n",
       "  'method',\n",
       "  'so',\n",
       "  'special',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'it',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'you',\n",
       "  'some',\n",
       "  'huge',\n",
       "  'money',\n",
       "  'on',\n",
       "  'autopilot',\n",
       "  'after',\n",
       "  'some',\n",
       "  'time',\n",
       "  'and',\n",
       "  'you',\n",
       "  'can',\n",
       "  'stay',\n",
       "  'lazy',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'does',\n",
       "  'this',\n",
       "  'work',\n",
       "  'worldwide',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'yup',\n",
       "  'this',\n",
       "  'can',\n",
       "  'work',\n",
       "  'anywhere',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'even',\n",
       "  'if',\n",
       "  'you',\n",
       "  're',\n",
       "  'from',\n",
       "  'another',\n",
       "  'country',\n",
       "  'color',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'how',\n",
       "  'can',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'you',\n",
       "  'are',\n",
       "  'able',\n",
       "  'to',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'in',\n",
       "  'btc',\n",
       "  'or',\n",
       "  'paypal',\n",
       "  'color'],\n",
       " [],\n",
       " ['color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'is',\n",
       "  'this',\n",
       "  'method',\n",
       "  'legal',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'legal',\n",
       "  'and',\n",
       "  'legit',\n",
       "  'it',\n",
       "  'whitehat',\n",
       "  'this',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'kind',\n",
       "  'method',\n",
       "  'color',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center', 'size', 'size', 'size', 'size', 'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'do',\n",
       "  'need',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'money',\n",
       "  'color'],\n",
       " ['size',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'no',\n",
       "  'no',\n",
       "  'and',\n",
       "  'no',\n",
       "  'color',\n",
       "  'size',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'does',\n",
       "  'this',\n",
       "  'require',\n",
       "  'hard',\n",
       "  'work',\n",
       "  'or',\n",
       "  'do',\n",
       "  'need',\n",
       "  'any',\n",
       "  'special',\n",
       "  'skills',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'size',\n",
       "  'it',\n",
       "  'only',\n",
       "  'takes',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'your',\n",
       "  'time',\n",
       "  'to',\n",
       "  'set',\n",
       "  'up',\n",
       "  'this',\n",
       "  'autopilot',\n",
       "  'method',\n",
       "  'after',\n",
       "  'that',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'fully',\n",
       "  'passive',\n",
       "  'and',\n",
       "  'automatic',\n",
       "  'and',\n",
       "  'your',\n",
       "  'only',\n",
       "  'job',\n",
       "  'from',\n",
       "  'that',\n",
       "  'moment',\n",
       "  'is',\n",
       "  'to',\n",
       "  'regularly',\n",
       "  'collect',\n",
       "  'your',\n",
       "  'earnings',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'size', 'size', 'size', 'size', 'center'],\n",
       " ['center', 'color', 'ffffff', 'size', 'download', 'size', 'color', 'center'],\n",
       " ['center',\n",
       "  'hide',\n",
       "  'url',\n",
       "  'https',\n",
       "  'finndev',\n",
       "  'net',\n",
       "  'hsd',\n",
       "  'obm',\n",
       "  'pdf',\n",
       "  'https',\n",
       "  'finndev',\n",
       "  'net',\n",
       "  'hsd',\n",
       "  'obm',\n",
       "  'pdf',\n",
       "  'url'],\n",
       " ['no',\n",
       "  'virus',\n",
       "  'https',\n",
       "  'www',\n",
       "  'virustotal',\n",
       "  'com',\n",
       "  'file',\n",
       "  'fb',\n",
       "  'be',\n",
       "  'bbf',\n",
       "  'cbfb',\n",
       "  'de',\n",
       "  'dc',\n",
       "  'ec',\n",
       "  'ad',\n",
       "  'dbf',\n",
       "  'detection',\n",
       "  'hide',\n",
       "  'center'],\n",
       " ['using', 'system', 'drawing'],\n",
       " ['using', 'system', 'drawing', 'text'],\n",
       " ['using', 'system', 'linq'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['summary',\n",
       "  'check',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'arial',\n",
       "  'regular',\n",
       "  'system',\n",
       "  'font',\n",
       "  'is',\n",
       "  'installed',\n",
       "  'summary'],\n",
       " ['public', 'static', 'bool'],\n",
       " [],\n",
       " ['get'],\n",
       " [],\n",
       " ['bool', 'result'],\n",
       " ['using', 'new'],\n",
       " ['fontfamily', 'fontfamilies', 'families'],\n",
       " ['fontfamily', 'ff', 'fontfamilies', 'firstordefault', 'name', 'arial'],\n",
       " ['result', 'ff', 'null', 'ff', 'fontstyle', 'regular'],\n",
       " [],\n",
       " ['return', 'result'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'hindi',\n",
       "  'free',\n",
       "  'download',\n",
       "  'gp'],\n",
       " ['http', 'urllie', 'com', 'mncg'],\n",
       " ['copy', 'paste', 'link'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['xnxx',\n",
       "  'com',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'search',\n",
       "  'free',\n",
       "  'sex',\n",
       "  'threesome',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'sexy',\n",
       "  'ladies',\n",
       "  'arranged',\n",
       "  'marriage',\n",
       "  'dressing',\n",
       "  'taylor',\n",
       "  'bra',\n",
       "  'salesman',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'shop',\n",
       "  'tailor',\n",
       "  'hindi',\n",
       "  'full',\n",
       "  'download',\n",
       "  'oldd',\n",
       "  'iss',\n",
       "  'goldd',\n",
       "  'hindi',\n",
       "  'dubbed',\n",
       "  'movie',\n",
       "  'gp',\n",
       "  'free',\n",
       "  'apaharan',\n",
       "  'full',\n",
       "  'hd',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'kannada',\n",
       "  'movie',\n",
       "  'my',\n",
       "  'wife',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'hindi'],\n",
       " [],\n",
       " ['trending',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'and',\n",
       "  'shows',\n",
       "  'sacred',\n",
       "  'games',\n",
       "  'sanju',\n",
       "  'race',\n",
       "  'it',\n",
       "  'an',\n",
       "  'interesting',\n",
       "  'movie',\n",
       "  'no',\n",
       "  'doubt',\n",
       "  'our',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hero',\n",
       "  'is',\n",
       "  'mehboob',\n",
       "  'start',\n",
       "  'your',\n",
       "  'free',\n",
       "  'trial',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'online',\n",
       "  'free',\n",
       "  'download',\n",
       "  'fashion',\n",
       "  'quality',\n",
       "  'movie',\n",
       "  'mobile',\n",
       "  'mp',\n",
       "  'gp',\n",
       "  'mkv',\n",
       "  'free',\n",
       "  'download',\n",
       "  'hindi',\n",
       "  'dubbed',\n",
       "  'full',\n",
       "  'movie'],\n",
       " [],\n",
       " ['flv',\n",
       "  'gp',\n",
       "  'wav',\n",
       "  'formats',\n",
       "  'free',\n",
       "  'download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'mp',\n",
       "  'hd',\n",
       "  'this',\n",
       "  'video',\n",
       "  'and',\n",
       "  'mp',\n",
       "  'song',\n",
       "  'of',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'telugu',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'of',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hindi',\n",
       "  'short',\n",
       "  'film',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'raju',\n",
       "  'gari',\n",
       "  'gadhi',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'telugu',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'thiruttuvcd'],\n",
       " [],\n",
       " ['download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'rajpal',\n",
       "  'yadav',\n",
       "  'videos',\n",
       "  'using',\n",
       "  'mp',\n",
       "  'hd',\n",
       "  'webm',\n",
       "  'mkv',\n",
       "  'flv',\n",
       "  'gp',\n",
       "  'wav',\n",
       "  'formats',\n",
       "  'free',\n",
       "  'ankur',\n",
       "  'arora',\n",
       "  'murder',\n",
       "  'case',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'ajay',\n",
       "  'devgan',\n",
       "  'full',\n",
       "  'movies',\n",
       "  'bollywood',\n",
       "  'full',\n",
       "  'movies'],\n",
       " [],\n",
       " ['tags',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'songs',\n",
       "  'video',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'bollywood',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'gp',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'download',\n",
       "  'mp',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'hindi',\n",
       "  'movie',\n",
       "  'songs',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'in',\n",
       "  'hindi',\n",
       "  'avi',\n",
       "  'movie',\n",
       "  'tamil',\n",
       "  'avi',\n",
       "  'telugu',\n",
       "  'gp',\n",
       "  'dowanload',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hdrip',\n",
       "  'telugu',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'watch',\n",
       "  'download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'dvd',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'full',\n",
       "  'hd',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'in',\n",
       "  'gp',\n",
       "  'free',\n",
       "  'hd',\n",
       "  'kya',\n",
       "  'garam',\n",
       "  'hai',\n",
       "  'hum',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'in',\n",
       "  'hindi'],\n",
       " ['kwerulantów'],\n",
       " ['kwerulanty'],\n",
       " ['kwerulencja'],\n",
       " ['kwerulencjach'],\n",
       " ['kwerulencjami'],\n",
       " ['kwerulencją'],\n",
       " ['kwerulencje'],\n",
       " ['kwerulencję'],\n",
       " ['kwerulencji'],\n",
       " ['kwerulencjo'],\n",
       " ['kwerulencjom'],\n",
       " ['kwerulencyj'],\n",
       " ['kwest'],\n",
       " ['kwesta'],\n",
       " ['kwestach'],\n",
       " ['kwestami'],\n",
       " ['kwestarce'],\n",
       " ['kwestarek'],\n",
       " ['kwestarka'],\n",
       " ['kwestarkach'],\n",
       " ['kwestarkami'],\n",
       " ['kwestarką'],\n",
       " ['kwestarkę'],\n",
       " ['kwestarki'],\n",
       " ['kwestarko'],\n",
       " ['kwestarkom'],\n",
       " ['kwestarscy'],\n",
       " ['kwestarska'],\n",
       " ['kwestarską'],\n",
       " ['kwestarski'],\n",
       " ['kwestarskich'],\n",
       " ['kwestarskie'],\n",
       " ['kwestarskiego'],\n",
       " ['kwestarskiej'],\n",
       " ['kwestarskiemu'],\n",
       " ['kwestarskim'],\n",
       " ['kwestarskimi'],\n",
       " ['kwestarsko'],\n",
       " ['kwestarskości'],\n",
       " ['kwestarskością'],\n",
       " ['kwestarskościom'],\n",
       " ['kwestarskość'],\n",
       " ['kwestarsku'],\n",
       " ['kwestarz'],\n",
       " ['kwestarza'],\n",
       " ['kwestarzach'],\n",
       " ['kwestarzami'],\n",
       " ['kwestarze'],\n",
       " ['kwestarzem'],\n",
       " ['kwestarzom'],\n",
       " ['kwestarzowi'],\n",
       " ['kwestarzów'],\n",
       " ['kwestarzu'],\n",
       " ['kwestarzy'],\n",
       " ['kwestą'],\n",
       " ['kwestę'],\n",
       " ['kwestia'],\n",
       " ['kwestiach'],\n",
       " ['kwestiami'],\n",
       " ['kwestią'],\n",
       " ['kwestie'],\n",
       " ['kwestię'],\n",
       " ['kwestii'],\n",
       " ['kwestio'],\n",
       " ['kwestiom'],\n",
       " ['kwestionariusz'],\n",
       " ['kwestionariusza'],\n",
       " ['kwestionariusze'],\n",
       " ['kwestionariuszu'],\n",
       " ['kwestionariuszy'],\n",
       " ['kwestionować'],\n",
       " ['kwestionowali'],\n",
       " ['kwestionowaliby'],\n",
       " ['kwestionowalna'],\n",
       " ['kwestionowalną'],\n",
       " ['kwestionowalne'],\n",
       " ['kwestionowalnej'],\n",
       " ['kwestionowalni'],\n",
       " ['kwestionowalny'],\n",
       " ['kwestionowalnym'],\n",
       " ['kwestionował'],\n",
       " ['kwestionowała'],\n",
       " ['kwestionowałaby'],\n",
       " ['kwestionowałam'],\n",
       " ['kwestionowałaś'],\n",
       " ['kwestionowałby'],\n",
       " ['kwestionowałbym'],\n",
       " ['kwestionowałbyś'],\n",
       " ['kwestionowałem'],\n",
       " ['kwestionowałeś'],\n",
       " ['kwestionowało'],\n",
       " ['kwestionowałoby'],\n",
       " ['kwestionowały'],\n",
       " ['kwestionowałyby'],\n",
       " ['kwestionowana'],\n",
       " ['kwestionowaną'],\n",
       " ['kwestionowane'],\n",
       " ['kwestionowanego'],\n",
       " ['kwestionowanej'],\n",
       " ['kwestionowanemu'],\n",
       " ['kwestionowani'],\n",
       " ['kwestionowania'],\n",
       " ['kwestionowanie'],\n",
       " ['kwestionowaniem'],\n",
       " ['kwestionowaniom'],\n",
       " ['kwestionowaniu'],\n",
       " ['kwestionowano'],\n",
       " ['kwestionowany'],\n",
       " ['kwestionowanych'],\n",
       " ['kwestionowanym'],\n",
       " ['kwestionowanymi'],\n",
       " ['kwestionowań'],\n",
       " ['kwestionuj'],\n",
       " ['kwestionują'],\n",
       " ['kwestionując'],\n",
       " ['kwestionująca'],\n",
       " ['kwestionującą'],\n",
       " ['kwestionujące'],\n",
       " ['kwestionującego'],\n",
       " ['kwestionującej'],\n",
       " ['kwestionującemu'],\n",
       " ['kwestionujący'],\n",
       " ['kwestionujących'],\n",
       " ['kwestionującym'],\n",
       " ['kwestionującymi'],\n",
       " ['kwestionujcie'],\n",
       " ['kwestionujcież'],\n",
       " ['kwestionuje'],\n",
       " ['kwestionujecie'],\n",
       " ['kwestionujemy'],\n",
       " ['kwestionujesz'],\n",
       " ['kwestionuję'],\n",
       " ['kwestionujmy'],\n",
       " ['kwestionujmyż'],\n",
       " ['kwestionujże'],\n",
       " ['kwesto'],\n",
       " ['kwestom'],\n",
       " ['kwestor'],\n",
       " ['kwestora'],\n",
       " ['kwestorach'],\n",
       " ['kwestorami'],\n",
       " ['kwestorce'],\n",
       " ['kwestorek'],\n",
       " ['kwestorem'],\n",
       " ['kwestorka'],\n",
       " ['kwestorkach'],\n",
       " ['kwestorkami'],\n",
       " ['kwestorką'],\n",
       " ['kwestorkę'],\n",
       " ['kwestorki'],\n",
       " ['kwestorko'],\n",
       " ['kwestorkom'],\n",
       " ['kwestorom'],\n",
       " ['kwestorowi'],\n",
       " ['kwestorów'],\n",
       " ['kwestorscy'],\n",
       " ['kwestorska'],\n",
       " ['kwestorską'],\n",
       " ['kwestorski'],\n",
       " ['kwestorskich'],\n",
       " ['kwestorskie'],\n",
       " ['kwestorskiego'],\n",
       " ['kwestorskiej'],\n",
       " ['kwestorskiemu'],\n",
       " ['kwestorskim'],\n",
       " ['kwestorskimi'],\n",
       " ['kwestorsko'],\n",
       " ['kwestorskości'],\n",
       " ['kwestorskością'],\n",
       " ['kwestorskościom'],\n",
       " ['kwestorskość'],\n",
       " ['kwestorsku'],\n",
       " ['kwestory'],\n",
       " ['kwestorze'],\n",
       " ['kwestorzy'],\n",
       " ['kwestować'],\n",
       " ['kwestowali'],\n",
       " ['kwestowaliby'],\n",
       " ['kwestowalibyśmy'],\n",
       " ['kwestowaliście'],\n",
       " ['kwestowaliśmy'],\n",
       " ['kwestował'],\n",
       " ['kwestowała'],\n",
       " ['kwestowałaby'],\n",
       " ['kwestowałabym'],\n",
       " ['kwestowałabyś'],\n",
       " ['kwestowałam'],\n",
       " ['kwestowałaś'],\n",
       " ['kwestowałby'],\n",
       " ['kwestowałbym'],\n",
       " ['kwestowałbyś'],\n",
       " ['kwestowałem'],\n",
       " ['kwestowałeś'],\n",
       " ['kwestowało'],\n",
       " ['kwestowałoby'],\n",
       " ['kwestowały'],\n",
       " ['kwestowałyby'],\n",
       " ['kwestowałybyśmy'],\n",
       " ['kwestowałyście'],\n",
       " ['kwestowałyśmy'],\n",
       " ['kwestowania'],\n",
       " ['kwestowaniach'],\n",
       " ['kwestowaniami'],\n",
       " ['kwestowanie'],\n",
       " ['kwestowaniem'],\n",
       " ['kwestowaniom'],\n",
       " ['kwestowaniu'],\n",
       " ['kwestowano'],\n",
       " ['kwestowań'],\n",
       " ['kwestuj'],\n",
       " ['kwestują'],\n",
       " ['kwestując'],\n",
       " ['kwestująca'],\n",
       " ['kwestującą'],\n",
       " ['kwestujące'],\n",
       " ['kwestującego'],\n",
       " ['kwestującej'],\n",
       " ['kwestującemu'],\n",
       " ['kwestujący'],\n",
       " ['kwestujących'],\n",
       " ['kwestującym'],\n",
       " ['kwestującymi'],\n",
       " ['kwestujcie'],\n",
       " ['kwestujcież'],\n",
       " ['kwestuje'],\n",
       " ['kwestujecie'],\n",
       " ['kwestujemy'],\n",
       " ['kwestujesz'],\n",
       " ['kwestuję'],\n",
       " ['kwestujmy'],\n",
       " ['kwestujmyż'],\n",
       " ['kwestujże'],\n",
       " ['kwestur'],\n",
       " ['kwestura'],\n",
       " ['kwesturach'],\n",
       " ['kwesturami'],\n",
       " ['kwesturą'],\n",
       " ['kwesturę'],\n",
       " ['kwesturo'],\n",
       " ['kwesturom'],\n",
       " ['kwestury'],\n",
       " ['kwesturze'],\n",
       " ['kwesty'],\n",
       " ['kwestyj'],\n",
       " ['kwestyjce'],\n",
       " ['kwestyjek'],\n",
       " ['kwestyjka'],\n",
       " ['kwestyjkach'],\n",
       " ['kwestyjkami'],\n",
       " ['kwestyjką'],\n",
       " ['kwestyjkę'],\n",
       " ['kwestyjki'],\n",
       " ['kwestyjko'],\n",
       " ['kwestyjkom'],\n",
       " ['kweście'],\n",
       " ['kwezal'],\n",
       " ['kwezala'],\n",
       " ['kwezalach'],\n",
       " ['kwezalami'],\n",
       " ['kwezale'],\n",
       " ['kwezalem'],\n",
       " ['kwezali'],\n",
       " ['kwezalom'],\n",
       " ['kwezalowi'],\n",
       " ['kwezalu'],\n",
       " ['kwęcz'],\n",
       " ['kwęczał'],\n",
       " ['kwęczała'],\n",
       " ['kwęczałaby'],\n",
       " ['kwęczałabym'],\n",
       " ['kwęczałabyś'],\n",
       " ['kwęczałam'],\n",
       " ['kwęczałaś'],\n",
       " ['kwęczałby'],\n",
       " ['kwęczałbym'],\n",
       " ['kwęczałbyś'],\n",
       " ['kwęczałem'],\n",
       " ['kwęczałeś'],\n",
       " ['kwęczało'],\n",
       " ['kwęczałoby'],\n",
       " ['kwęczały'],\n",
       " ['kwęczałyby'],\n",
       " ['kwęczałybyście'],\n",
       " ['kwęczałybyśmy'],\n",
       " ['kwęczałyście'],\n",
       " ['kwęczałyśmy'],\n",
       " ['kwęczano'],\n",
       " ['kwęczą'],\n",
       " ['kwęcząc'],\n",
       " ['kwęcząca'],\n",
       " ['kwęczącą'],\n",
       " ['kwęczące'],\n",
       " ['kwęczącego'],\n",
       " ['kwęczącej'],\n",
       " ['kwęczącemu'],\n",
       " ['kwęczący'],\n",
       " ['kwęczących'],\n",
       " ['kwęczącym'],\n",
       " ['kwęczącymi'],\n",
       " ['kwęczcie'],\n",
       " ['kwęczcież'],\n",
       " ['kwęczeć'],\n",
       " ['kwęczeli'],\n",
       " ['kwęczeliby'],\n",
       " ['kwęczelibyście'],\n",
       " ['kwęczelibyśmy'],\n",
       " ['kwęczeliście'],\n",
       " ['kwęczeliśmy'],\n",
       " ['kwęczenia'],\n",
       " ['kwęczeniach'],\n",
       " ['kwęczeniami'],\n",
       " ['kwęczenie'],\n",
       " ['kwęczeniem'],\n",
       " ['kwęczeniom'],\n",
       " ['kwęczeniu'],\n",
       " ['kwęczeń'],\n",
       " ['kwęczę'],\n",
       " ['kwęczmy'],\n",
       " ['kwęczmyż'],\n",
       " ['kwęczy'],\n",
       " ['kwęczycie'],\n",
       " ['kwęczymy'],\n",
       " ...]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 16:43:52,916 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 16:43:52,917 : INFO : collecting all words and their counts\n",
      "2019-09-14 16:43:52,917 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 16:43:52,925 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 16:43:52,935 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 16:43:52,944 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 16:43:52,953 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 16:43:52,961 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 16:43:52,969 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 16:43:52,977 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 16:43:52,985 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 16:43:52,995 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 16:43:53,003 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 16:43:53,011 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 16:43:53,019 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 16:43:53,027 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 16:43:53,035 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 16:43:53,043 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 16:43:53,051 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 16:43:53,060 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 16:43:53,068 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 16:43:53,076 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 16:43:53,085 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 16:43:53,094 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 16:43:53,106 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 16:43:53,114 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 16:43:53,122 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 16:43:53,130 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 16:43:53,138 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 16:43:53,146 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 16:43:53,155 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 16:43:53,164 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 16:43:53,172 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 16:43:53,180 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 16:43:53,189 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 16:43:53,199 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 16:43:53,207 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 16:43:53,216 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 16:43:53,225 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 16:43:53,233 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 16:43:53,242 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 16:43:53,252 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 16:43:53,260 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 16:43:53,268 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 16:43:53,277 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 16:43:53,285 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 16:43:53,294 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 16:43:53,304 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 16:43:53,314 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 16:43:53,324 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 16:43:53,333 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 16:43:53,345 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 16:43:53,355 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 16:43:53,362 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 16:43:53,372 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 16:43:53,380 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 16:43:53,389 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 16:43:53,398 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 16:43:53,406 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 16:43:53,420 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 16:43:53,429 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 16:43:53,437 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 16:43:53,446 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 16:43:53,453 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 16:43:53,461 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 16:43:53,470 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 16:43:53,478 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 16:43:53,487 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 16:43:53,495 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 16:43:53,505 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 16:43:53,513 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 16:43:53,521 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 16:43:53,530 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 16:43:53,538 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 16:43:53,547 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 16:43:53,555 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 16:43:53,563 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 16:43:53,571 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 16:43:53,579 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 16:43:53,586 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 16:43:53,587 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 16:43:54,041 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 16:43:54,042 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 16:43:54,553 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 16:43:54,556 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 16:43:54,557 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 16:43:55,037 : INFO : estimated required memory for 215409 words and 150 dimensions: 366195300 bytes\n",
      "2019-09-14 16:43:55,037 : INFO : resetting layer weights\n",
      "2019-09-14 16:43:56,701 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 16:43:57,722 : INFO : EPOCH 1 - PROGRESS: at 53.62% examples, 1432111 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 16:43:58,490 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:43:58,503 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:43:58,504 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:43:58,508 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:43:58,511 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:43:58,516 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:43:58,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:43:58,517 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:43:58,519 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:43:58,524 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:43:58,524 : INFO : EPOCH - 1 : training on 2850148 raw words (2683709 effective words) took 1.8s, 1479499 effective words/s\n",
      "2019-09-14 16:43:59,538 : INFO : EPOCH 2 - PROGRESS: at 54.31% examples, 1460736 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-14 16:44:00,309 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:00,310 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:00,311 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:00,312 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:00,314 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:00,315 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:00,315 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:00,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:00,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:00,320 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:00,320 : INFO : EPOCH - 2 : training on 2850148 raw words (2683598 effective words) took 1.8s, 1501411 effective words/s\n",
      "2019-09-14 16:44:01,329 : INFO : EPOCH 3 - PROGRESS: at 56.18% examples, 1513936 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 16:44:02,043 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:02,048 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:02,048 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:02,048 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:02,052 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:02,062 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:02,063 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:02,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:02,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:02,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:02,064 : INFO : EPOCH - 3 : training on 2850148 raw words (2683865 effective words) took 1.7s, 1545998 effective words/s\n",
      "2019-09-14 16:44:03,075 : INFO : EPOCH 4 - PROGRESS: at 50.09% examples, 1350180 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:03,945 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:03,947 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:03,947 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:03,947 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:03,952 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:03,953 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:03,954 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:03,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:03,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:03,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:03,963 : INFO : EPOCH - 4 : training on 2850148 raw words (2683867 effective words) took 1.9s, 1419630 effective words/s\n",
      "2019-09-14 16:44:04,972 : INFO : EPOCH 5 - PROGRESS: at 53.91% examples, 1458527 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 16:44:05,771 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:05,783 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:05,787 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:05,792 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:05,794 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:05,795 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:05,796 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:05,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:05,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:05,801 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:05,802 : INFO : EPOCH - 5 : training on 2850148 raw words (2684437 effective words) took 1.8s, 1466739 effective words/s\n",
      "2019-09-14 16:44:05,802 : INFO : training on a 14250740 raw words (13419476 effective words) took 9.1s, 1474701 effective words/s\n",
      "2019-09-14 16:44:05,857 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 16:44:05,857 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 16:44:06,868 : INFO : EPOCH 1 - PROGRESS: at 51.46% examples, 1388819 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:07,712 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:07,715 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:07,717 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 16:44:07,721 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:07,732 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:07,732 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:07,733 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:07,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:07,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:07,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:07,739 : INFO : EPOCH - 1 : training on 2850148 raw words (2684230 effective words) took 1.9s, 1432699 effective words/s\n",
      "2019-09-14 16:44:08,749 : INFO : EPOCH 2 - PROGRESS: at 53.21% examples, 1437820 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 16:44:09,576 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:09,578 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:09,581 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:09,581 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:09,585 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:09,588 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:09,590 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:09,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:09,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:09,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:09,592 : INFO : EPOCH - 2 : training on 2850148 raw words (2683725 effective words) took 1.8s, 1455086 effective words/s\n",
      "2019-09-14 16:44:10,608 : INFO : EPOCH 3 - PROGRESS: at 52.82% examples, 1418872 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:11,436 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:11,438 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:11,439 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:11,448 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:11,449 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:11,452 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:11,453 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:11,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:11,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:11,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:11,459 : INFO : EPOCH - 3 : training on 2850148 raw words (2683741 effective words) took 1.9s, 1443906 effective words/s\n",
      "2019-09-14 16:44:12,482 : INFO : EPOCH 4 - PROGRESS: at 53.22% examples, 1418299 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-14 16:44:13,263 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:13,275 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:13,283 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:13,284 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:13,290 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:13,291 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:13,293 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:13,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:13,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:13,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:13,301 : INFO : EPOCH - 4 : training on 2850148 raw words (2683612 effective words) took 1.8s, 1463074 effective words/s\n",
      "2019-09-14 16:44:14,311 : INFO : EPOCH 5 - PROGRESS: at 54.02% examples, 1456629 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 16:44:15,069 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:15,091 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:15,092 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:15,094 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:15,095 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:15,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:15,098 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:15,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:15,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:15,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:15,103 : INFO : EPOCH - 5 : training on 2850148 raw words (2683518 effective words) took 1.8s, 1496526 effective words/s\n",
      "2019-09-14 16:44:16,118 : INFO : EPOCH 6 - PROGRESS: at 53.93% examples, 1449679 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-14 16:44:16,845 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:16,857 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:16,864 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:16,865 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:16,869 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:16,869 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:16,870 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:16,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:16,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:16,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:16,872 : INFO : EPOCH - 6 : training on 2850148 raw words (2684068 effective words) took 1.8s, 1523998 effective words/s\n",
      "2019-09-14 16:44:17,885 : INFO : EPOCH 7 - PROGRESS: at 53.21% examples, 1432965 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:18,631 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:18,633 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:18,633 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:18,634 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:18,635 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:18,643 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:18,643 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:18,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:18,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:18,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:18,649 : INFO : EPOCH - 7 : training on 2850148 raw words (2683465 effective words) took 1.8s, 1517870 effective words/s\n",
      "2019-09-14 16:44:19,663 : INFO : EPOCH 8 - PROGRESS: at 52.14% examples, 1403124 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:20,439 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:20,441 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:20,443 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:20,446 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 16:44:20,449 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:20,452 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:20,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:20,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:20,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:20,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:20,454 : INFO : EPOCH - 8 : training on 2850148 raw words (2683517 effective words) took 1.8s, 1492972 effective words/s\n",
      "2019-09-14 16:44:21,470 : INFO : EPOCH 9 - PROGRESS: at 53.39% examples, 1429448 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 16:44:22,231 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:22,238 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:22,241 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:22,243 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:22,246 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:22,252 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:22,254 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:22,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:22,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:22,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:22,259 : INFO : EPOCH - 9 : training on 2850148 raw words (2683864 effective words) took 1.8s, 1494967 effective words/s\n",
      "2019-09-14 16:44:23,269 : INFO : EPOCH 10 - PROGRESS: at 50.08% examples, 1350460 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-14 16:44:24,172 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 16:44:24,175 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 16:44:24,175 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 16:44:24,185 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 16:44:24,187 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 16:44:24,188 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 16:44:24,192 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 16:44:24,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 16:44:24,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 16:44:24,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 16:44:24,203 : INFO : EPOCH - 10 : training on 2850148 raw words (2683862 effective words) took 1.9s, 1385980 effective words/s\n",
      "2019-09-14 16:44:24,203 : INFO : training on a 28501480 raw words (26837602 effective words) took 18.3s, 1462858 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26837602, 28501480)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=5, min_count=1, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:06:45,086 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 17:06:45,087 : INFO : collecting all words and their counts\n",
      "2019-09-14 17:06:45,087 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 17:06:45,095 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 17:06:45,105 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 17:06:45,113 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 17:06:45,121 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 17:06:45,129 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 17:06:45,137 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 17:06:45,144 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 17:06:45,152 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 17:06:45,161 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 17:06:45,168 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 17:06:45,176 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 17:06:45,184 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 17:06:45,191 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 17:06:45,198 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 17:06:45,206 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 17:06:45,213 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 17:06:45,221 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 17:06:45,229 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 17:06:45,237 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 17:06:45,246 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 17:06:45,254 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 17:06:45,265 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 17:06:45,273 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 17:06:45,281 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 17:06:45,289 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 17:06:45,296 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 17:06:45,303 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 17:06:45,312 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 17:06:45,320 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 17:06:45,328 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 17:06:45,336 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 17:06:45,345 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 17:06:45,354 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 17:06:45,361 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 17:06:45,370 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 17:06:45,378 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 17:06:45,386 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 17:06:45,395 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 17:06:45,405 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 17:06:45,413 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 17:06:45,422 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 17:06:45,430 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 17:06:45,439 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 17:06:45,447 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 17:06:45,456 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 17:06:45,465 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 17:06:45,475 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 17:06:45,483 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 17:06:45,492 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 17:06:45,501 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 17:06:45,508 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 17:06:45,517 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 17:06:45,525 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 17:06:45,533 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 17:06:45,542 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 17:06:45,549 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 17:06:45,562 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 17:06:45,570 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 17:06:45,578 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 17:06:45,586 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 17:06:45,594 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 17:06:45,601 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 17:06:45,609 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 17:06:45,617 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 17:06:45,625 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 17:06:45,632 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 17:06:45,641 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 17:06:45,649 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 17:06:45,657 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 17:06:45,665 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:06:45,672 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 17:06:45,680 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 17:06:45,688 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 17:06:45,695 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 17:06:45,703 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 17:06:45,711 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 17:06:45,717 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 17:06:45,717 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 17:06:46,199 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 17:06:46,199 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 17:06:46,694 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 17:06:46,698 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 17:06:46,698 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 17:06:47,183 : INFO : estimated required memory for 215409 words and 350 dimensions: 710849700 bytes\n",
      "2019-09-14 17:06:47,184 : INFO : resetting layer weights\n",
      "2019-09-14 17:06:49,271 : INFO : training model with 10 workers on 215409 vocabulary and 350 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:06:50,290 : INFO : EPOCH 1 - PROGRESS: at 46.80% examples, 1247893 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:06:51,291 : INFO : EPOCH 1 - PROGRESS: at 90.55% examples, 1211684 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:06:51,408 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:06:51,409 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:06:51,413 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:06:51,413 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:06:51,414 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:06:51,425 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:06:51,427 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:06:51,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:06:51,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:06:51,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:06:51,429 : INFO : EPOCH - 1 : training on 2850148 raw words (2683643 effective words) took 2.1s, 1248802 effective words/s\n",
      "2019-09-14 17:06:52,438 : INFO : EPOCH 2 - PROGRESS: at 44.82% examples, 1202678 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-14 17:06:53,446 : INFO : EPOCH 2 - PROGRESS: at 87.10% examples, 1166008 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:06:53,617 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:06:53,622 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:06:53,625 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:06:53,640 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:06:53,643 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:06:53,649 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:06:53,650 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:06:53,651 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:06:53,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:06:53,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:06:53,657 : INFO : EPOCH - 2 : training on 2850148 raw words (2683716 effective words) took 2.2s, 1208800 effective words/s\n",
      "2019-09-14 17:06:54,666 : INFO : EPOCH 3 - PROGRESS: at 46.09% examples, 1240176 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:06:55,672 : INFO : EPOCH 3 - PROGRESS: at 94.59% examples, 1265692 words/s, in_qsize 16, out_qsize 0\n",
      "2019-09-14 17:06:55,716 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:06:55,726 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:06:55,727 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:06:55,737 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:06:55,742 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:06:55,743 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:06:55,744 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:06:55,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:06:55,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:06:55,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:06:55,753 : INFO : EPOCH - 3 : training on 2850148 raw words (2683317 effective words) took 2.1s, 1285612 effective words/s\n",
      "2019-09-14 17:06:56,768 : INFO : EPOCH 4 - PROGRESS: at 45.48% examples, 1213386 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-14 17:06:57,779 : INFO : EPOCH 4 - PROGRESS: at 94.53% examples, 1258613 words/s, in_qsize 16, out_qsize 0\n",
      "2019-09-14 17:06:57,828 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:06:57,829 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:06:57,848 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:06:57,848 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:06:57,849 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:06:57,850 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:06:57,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:06:57,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:06:57,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:06:57,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:06:57,857 : INFO : EPOCH - 4 : training on 2850148 raw words (2683294 effective words) took 2.1s, 1280049 effective words/s\n",
      "2019-09-14 17:06:58,871 : INFO : EPOCH 5 - PROGRESS: at 46.09% examples, 1234398 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:06:59,883 : INFO : EPOCH 5 - PROGRESS: at 89.85% examples, 1198615 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:00,021 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:00,026 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:00,028 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:00,029 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:00,045 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:00,046 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:00,047 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:00,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:00,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:00,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:00,050 : INFO : EPOCH - 5 : training on 2850148 raw words (2684130 effective words) took 2.2s, 1228553 effective words/s\n",
      "2019-09-14 17:07:00,051 : INFO : training on a 14250740 raw words (13418100 effective words) took 10.8s, 1244939 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:00,115 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 17:07:00,116 : INFO : training model with 10 workers on 215409 vocabulary and 350 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:07:01,128 : INFO : EPOCH 1 - PROGRESS: at 44.48% examples, 1194761 words/s, in_qsize 19, out_qsize 3\n",
      "2019-09-14 17:07:02,132 : INFO : EPOCH 1 - PROGRESS: at 94.59% examples, 1267688 words/s, in_qsize 16, out_qsize 0\n",
      "2019-09-14 17:07:02,188 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:02,191 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:02,196 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:02,205 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:02,206 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:02,207 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:02,209 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:02,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:02,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:02,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:02,219 : INFO : EPOCH - 1 : training on 2850148 raw words (2684151 effective words) took 2.1s, 1283443 effective words/s\n",
      "2019-09-14 17:07:03,250 : INFO : EPOCH 2 - PROGRESS: at 44.88% examples, 1199445 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-14 17:07:04,260 : INFO : EPOCH 2 - PROGRESS: at 90.27% examples, 1205460 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:04,359 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:04,363 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:04,371 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:04,372 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:04,378 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:04,384 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:04,386 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:04,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:04,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:04,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:04,397 : INFO : EPOCH - 2 : training on 2850148 raw words (2684071 effective words) took 2.2s, 1247464 effective words/s\n",
      "2019-09-14 17:07:05,405 : INFO : EPOCH 3 - PROGRESS: at 41.70% examples, 1119804 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:06,406 : INFO : EPOCH 3 - PROGRESS: at 86.46% examples, 1161552 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:06,606 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:06,617 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:06,620 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:06,620 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:06,635 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:06,636 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:06,638 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:06,642 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:06,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:06,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:06,656 : INFO : EPOCH - 3 : training on 2850148 raw words (2683734 effective words) took 2.3s, 1192471 effective words/s\n",
      "2019-09-14 17:07:07,673 : INFO : EPOCH 4 - PROGRESS: at 44.36% examples, 1192075 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:08,677 : INFO : EPOCH 4 - PROGRESS: at 93.02% examples, 1248288 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:08,747 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:08,759 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:08,761 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:08,762 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:08,763 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:08,765 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:08,767 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:08,770 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:08,771 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:08,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:08,774 : INFO : EPOCH - 4 : training on 2850148 raw words (2683373 effective words) took 2.1s, 1276774 effective words/s\n",
      "2019-09-14 17:07:09,788 : INFO : EPOCH 5 - PROGRESS: at 48.91% examples, 1314029 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:10,784 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:10,785 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:10,786 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:10,787 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:10,789 : INFO : EPOCH 5 - PROGRESS: at 98.80% examples, 1319763 words/s, in_qsize 5, out_qsize 1\n",
      "2019-09-14 17:07:10,790 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:10,795 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:10,799 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:10,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:10,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:10,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:10,809 : INFO : EPOCH - 5 : training on 2850148 raw words (2683636 effective words) took 2.0s, 1326022 effective words/s\n",
      "2019-09-14 17:07:11,821 : INFO : EPOCH 6 - PROGRESS: at 42.15% examples, 1124122 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:12,844 : INFO : EPOCH 6 - PROGRESS: at 88.02% examples, 1169938 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-14 17:07:12,985 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:12,996 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:13,005 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:13,010 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:13,011 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:13,013 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:13,016 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:13,017 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:13,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:13,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:13,021 : INFO : EPOCH - 6 : training on 2850148 raw words (2683600 effective words) took 2.2s, 1217531 effective words/s\n",
      "2019-09-14 17:07:14,032 : INFO : EPOCH 7 - PROGRESS: at 43.81% examples, 1172771 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-14 17:07:15,049 : INFO : EPOCH 7 - PROGRESS: at 92.28% examples, 1230046 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:07:15,117 : INFO : worker thread finished; awaiting finish of 9 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:15,118 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:15,130 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:15,134 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:15,136 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:15,138 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:15,139 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:15,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:15,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:15,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:15,145 : INFO : EPOCH - 7 : training on 2850148 raw words (2684033 effective words) took 2.1s, 1268827 effective words/s\n",
      "2019-09-14 17:07:16,188 : INFO : EPOCH 8 - PROGRESS: at 48.45% examples, 1263268 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:17,168 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:17,179 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:17,180 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:17,192 : INFO : EPOCH 8 - PROGRESS: at 98.20% examples, 1290550 words/s, in_qsize 6, out_qsize 1\n",
      "2019-09-14 17:07:17,192 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:17,193 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:17,195 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:17,197 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:17,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:17,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:17,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:17,209 : INFO : EPOCH - 8 : training on 2850148 raw words (2683787 effective words) took 2.1s, 1305592 effective words/s\n",
      "2019-09-14 17:07:18,220 : INFO : EPOCH 9 - PROGRESS: at 45.79% examples, 1229128 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:19,240 : INFO : EPOCH 9 - PROGRESS: at 89.97% examples, 1196187 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:07:19,353 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:19,355 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:19,358 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:19,366 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:19,372 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:19,377 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:19,378 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:19,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:19,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:19,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:19,393 : INFO : EPOCH - 9 : training on 2850148 raw words (2683640 effective words) took 2.2s, 1233488 effective words/s\n",
      "2019-09-14 17:07:20,401 : INFO : EPOCH 10 - PROGRESS: at 46.39% examples, 1250389 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:21,408 : INFO : EPOCH 10 - PROGRESS: at 95.73% examples, 1280384 words/s, in_qsize 13, out_qsize 0\n",
      "2019-09-14 17:07:21,423 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:21,433 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:21,437 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:21,441 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:21,442 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:21,450 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:21,451 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:21,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:21,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:21,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:21,458 : INFO : EPOCH - 10 : training on 2850148 raw words (2684256 effective words) took 2.1s, 1305288 effective words/s\n",
      "2019-09-14 17:07:21,458 : INFO : training on a 28501480 raw words (26838281 effective words) took 21.3s, 1257548 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26838281, 28501480)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_350 = gensim.models.Word2Vec (documents, size=350, window=5, min_count=1, workers=10)\n",
    "model_350.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:21,464 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 17:07:21,465 : INFO : collecting all words and their counts\n",
      "2019-09-14 17:07:21,465 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 17:07:21,473 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 17:07:21,481 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 17:07:21,490 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 17:07:21,498 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 17:07:21,506 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 17:07:21,513 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 17:07:21,521 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 17:07:21,529 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 17:07:21,538 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 17:07:21,545 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 17:07:21,552 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 17:07:21,560 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 17:07:21,567 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 17:07:21,574 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 17:07:21,581 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 17:07:21,588 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 17:07:21,596 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 17:07:21,603 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 17:07:21,611 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 17:07:21,619 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 17:07:21,627 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 17:07:21,637 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 17:07:21,644 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 17:07:21,651 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 17:07:21,659 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 17:07:21,666 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 17:07:21,673 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 17:07:21,681 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 17:07:21,689 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 17:07:21,696 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 17:07:21,704 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 17:07:21,712 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 17:07:21,720 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 17:07:21,727 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 17:07:21,735 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 17:07:21,743 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 17:07:21,750 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 17:07:21,758 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 17:07:21,767 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 17:07:21,774 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 17:07:21,782 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 17:07:21,790 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 17:07:21,798 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 17:07:21,805 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 17:07:21,814 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 17:07:21,822 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 17:07:21,831 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 17:07:21,839 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 17:07:21,847 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 17:07:21,855 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 17:07:21,862 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 17:07:21,870 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 17:07:21,877 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 17:07:21,885 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 17:07:21,893 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 17:07:21,900 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 17:07:21,912 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 17:07:21,920 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 17:07:21,928 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 17:07:21,936 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 17:07:21,942 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 17:07:21,949 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 17:07:21,956 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 17:07:21,963 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 17:07:21,971 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 17:07:21,977 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 17:07:21,985 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 17:07:21,992 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 17:07:21,999 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 17:07:22,006 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:22,012 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 17:07:22,019 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 17:07:22,026 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 17:07:22,033 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 17:07:22,039 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 17:07:22,046 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 17:07:22,051 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 17:07:22,052 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 17:07:22,557 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 17:07:22,558 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 17:07:23,047 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 17:07:23,051 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 17:07:23,051 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 17:07:23,548 : INFO : estimated required memory for 215409 words and 250 dimensions: 538522500 bytes\n",
      "2019-09-14 17:07:23,549 : INFO : resetting layer weights\n",
      "2019-09-14 17:07:25,363 : INFO : training model with 10 workers on 215409 vocabulary and 250 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:07:26,380 : INFO : EPOCH 1 - PROGRESS: at 48.70% examples, 1306562 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-14 17:07:27,298 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:27,315 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:27,317 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:27,318 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:27,324 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:27,326 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:27,327 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:27,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:27,329 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:27,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:27,338 : INFO : EPOCH - 1 : training on 2850148 raw words (2684221 effective words) took 2.0s, 1365296 effective words/s\n",
      "2019-09-14 17:07:28,350 : INFO : EPOCH 2 - PROGRESS: at 50.43% examples, 1357294 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:29,314 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:29,320 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:29,323 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:29,329 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:29,337 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:29,340 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:29,342 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:29,344 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:29,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:29,348 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:29,348 : INFO : EPOCH - 2 : training on 2850148 raw words (2683547 effective words) took 2.0s, 1340455 effective words/s\n",
      "2019-09-14 17:07:30,362 : INFO : EPOCH 3 - PROGRESS: at 45.56% examples, 1217092 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:31,366 : INFO : EPOCH 3 - PROGRESS: at 96.53% examples, 1287773 words/s, in_qsize 11, out_qsize 0\n",
      "2019-09-14 17:07:31,384 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:31,393 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:31,398 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:31,399 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:31,403 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:31,407 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:31,409 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:31,412 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:31,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:31,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:31,419 : INFO : EPOCH - 3 : training on 2850148 raw words (2684288 effective words) took 2.1s, 1301191 effective words/s\n",
      "2019-09-14 17:07:32,445 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 1304179 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:33,291 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:33,301 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:33,305 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:33,307 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:33,316 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:33,317 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:33,319 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:33,322 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:33,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:33,326 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:33,326 : INFO : EPOCH - 4 : training on 2850148 raw words (2683920 effective words) took 1.9s, 1413850 effective words/s\n",
      "2019-09-14 17:07:34,338 : INFO : EPOCH 5 - PROGRESS: at 49.49% examples, 1330125 words/s, in_qsize 17, out_qsize 3\n",
      "2019-09-14 17:07:35,206 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:35,215 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:35,222 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:35,223 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:35,224 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:35,224 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:35,227 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:35,229 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:35,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:35,234 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:35,234 : INFO : EPOCH - 5 : training on 2850148 raw words (2683563 effective words) took 1.9s, 1412386 effective words/s\n",
      "2019-09-14 17:07:35,235 : INFO : training on a 14250740 raw words (13419539 effective words) took 9.9s, 1359553 effective words/s\n",
      "2019-09-14 17:07:35,235 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 17:07:35,235 : INFO : training model with 10 workers on 215409 vocabulary and 250 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:07:36,252 : INFO : EPOCH 1 - PROGRESS: at 48.57% examples, 1296805 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:37,257 : INFO : EPOCH 1 - PROGRESS: at 93.82% examples, 1252939 words/s, in_qsize 18, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:37,308 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:37,321 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:37,321 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:37,326 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:37,333 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:37,334 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:37,336 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:37,337 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:37,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:37,339 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:37,339 : INFO : EPOCH - 1 : training on 2850148 raw words (2684214 effective words) took 2.1s, 1281036 effective words/s\n",
      "2019-09-14 17:07:38,347 : INFO : EPOCH 2 - PROGRESS: at 50.09% examples, 1352962 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:39,314 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:39,319 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:39,337 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:39,338 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:39,339 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:39,341 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:39,342 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:39,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:39,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:39,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:39,346 : INFO : EPOCH - 2 : training on 2850148 raw words (2683202 effective words) took 2.0s, 1342239 effective words/s\n",
      "2019-09-14 17:07:40,359 : INFO : EPOCH 3 - PROGRESS: at 50.46% examples, 1358257 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:41,205 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:41,207 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:41,209 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:41,216 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:41,217 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:41,223 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:41,224 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:41,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:41,229 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:41,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:41,232 : INFO : EPOCH - 3 : training on 2850148 raw words (2683386 effective words) took 1.9s, 1429401 effective words/s\n",
      "2019-09-14 17:07:42,244 : INFO : EPOCH 4 - PROGRESS: at 43.81% examples, 1171481 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:43,244 : INFO : EPOCH 4 - PROGRESS: at 91.23% examples, 1225470 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:07:43,338 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:43,340 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:43,349 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:43,351 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:43,363 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:43,364 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:43,365 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:43,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:43,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:43,373 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:43,373 : INFO : EPOCH - 4 : training on 2850148 raw words (2683934 effective words) took 2.1s, 1258217 effective words/s\n",
      "2019-09-14 17:07:44,398 : INFO : EPOCH 5 - PROGRESS: at 48.71% examples, 1285513 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:45,395 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:45,418 : INFO : EPOCH 5 - PROGRESS: at 97.64% examples, 1284314 words/s, in_qsize 7, out_qsize 3\n",
      "2019-09-14 17:07:45,419 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:45,419 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:45,422 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:45,429 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:45,430 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:45,435 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:45,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:45,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:45,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:45,445 : INFO : EPOCH - 5 : training on 2850148 raw words (2683854 effective words) took 2.1s, 1300732 effective words/s\n",
      "2019-09-14 17:07:46,466 : INFO : EPOCH 6 - PROGRESS: at 48.01% examples, 1271439 words/s, in_qsize 19, out_qsize 4\n",
      "2019-09-14 17:07:47,410 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:47,420 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:47,425 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:47,434 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:47,440 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:47,441 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:47,443 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:47,445 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:47,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:47,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:47,447 : INFO : EPOCH - 6 : training on 2850148 raw words (2683644 effective words) took 2.0s, 1345946 effective words/s\n",
      "2019-09-14 17:07:48,462 : INFO : EPOCH 7 - PROGRESS: at 45.86% examples, 1224203 words/s, in_qsize 18, out_qsize 9\n",
      "2019-09-14 17:07:49,466 : INFO : EPOCH 7 - PROGRESS: at 96.53% examples, 1286520 words/s, in_qsize 11, out_qsize 0\n",
      "2019-09-14 17:07:49,481 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:49,487 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:49,488 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:49,494 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:49,495 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:49,504 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:49,504 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:49,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:49,508 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:49,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:49,513 : INFO : EPOCH - 7 : training on 2850148 raw words (2683332 effective words) took 2.1s, 1303505 effective words/s\n",
      "2019-09-14 17:07:50,544 : INFO : EPOCH 8 - PROGRESS: at 48.64% examples, 1292317 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:07:51,509 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:51,523 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:51,524 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:51,528 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:51,534 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:51,536 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:51,537 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:51,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:51,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:51,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:51,542 : INFO : EPOCH - 8 : training on 2850148 raw words (2683824 effective words) took 2.0s, 1335524 effective words/s\n",
      "2019-09-14 17:07:52,572 : INFO : EPOCH 9 - PROGRESS: at 50.17% examples, 1347517 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-14 17:07:53,461 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:53,468 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:53,470 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:53,475 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:53,477 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:53,477 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:53,479 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:53,480 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:53,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:53,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:53,487 : INFO : EPOCH - 9 : training on 2850148 raw words (2683732 effective words) took 1.9s, 1397345 effective words/s\n",
      "2019-09-14 17:07:54,517 : INFO : EPOCH 10 - PROGRESS: at 51.43% examples, 1362542 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-14 17:07:55,402 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:07:55,407 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:07:55,414 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:07:55,416 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:07:55,420 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:07:55,424 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:07:55,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:07:55,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:07:55,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:07:55,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:07:55,433 : INFO : EPOCH - 10 : training on 2850148 raw words (2683865 effective words) took 1.9s, 1384942 effective words/s\n",
      "2019-09-14 17:07:55,433 : INFO : training on a 28501480 raw words (26836987 effective words) took 20.2s, 1328712 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26836987, 28501480)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_250 = gensim.models.Word2Vec (documents, size=250, window=5, min_count=1, workers=10)\n",
    "model_250.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:08:25,408 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 17:08:25,408 : INFO : collecting all words and their counts\n",
      "2019-09-14 17:08:25,409 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 17:08:25,416 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 17:08:25,424 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 17:08:25,432 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 17:08:25,440 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 17:08:25,447 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 17:08:25,454 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 17:08:25,461 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 17:08:25,468 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 17:08:25,477 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 17:08:25,484 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 17:08:25,491 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 17:08:25,498 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 17:08:25,505 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 17:08:25,512 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 17:08:25,519 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 17:08:25,526 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 17:08:25,534 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 17:08:25,541 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 17:08:25,549 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 17:08:25,558 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 17:08:25,566 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 17:08:25,577 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 17:08:25,584 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 17:08:25,592 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 17:08:25,600 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 17:08:25,607 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 17:08:25,614 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 17:08:25,622 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 17:08:25,630 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 17:08:25,638 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 17:08:25,646 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 17:08:25,654 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 17:08:25,663 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 17:08:25,670 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 17:08:25,678 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 17:08:25,686 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 17:08:25,694 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 17:08:25,702 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 17:08:25,711 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 17:08:25,718 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 17:08:25,725 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 17:08:25,733 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 17:08:25,740 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 17:08:25,747 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 17:08:25,755 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 17:08:25,763 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 17:08:25,771 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 17:08:25,778 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 17:08:25,786 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 17:08:25,793 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 17:08:25,800 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 17:08:25,808 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 17:08:25,815 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 17:08:25,822 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 17:08:25,829 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 17:08:25,836 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 17:08:25,847 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 17:08:25,854 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 17:08:25,861 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 17:08:25,869 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 17:08:25,875 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 17:08:25,883 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 17:08:25,891 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 17:08:25,899 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 17:08:25,907 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 17:08:25,914 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 17:08:25,923 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 17:08:25,930 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 17:08:25,937 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 17:08:25,945 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:08:25,952 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 17:08:25,959 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 17:08:25,966 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 17:08:25,972 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 17:08:25,979 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 17:08:25,986 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 17:08:25,991 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 17:08:25,992 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 17:08:26,276 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 17:08:26,277 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 17:08:26,770 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 17:08:26,773 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 17:08:26,774 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 17:08:27,260 : INFO : estimated required memory for 215409 words and 50 dimensions: 193868100 bytes\n",
      "2019-09-14 17:08:27,261 : INFO : resetting layer weights\n",
      "2019-09-14 17:08:28,628 : INFO : training model with 10 workers on 215409 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:08:29,641 : INFO : EPOCH 1 - PROGRESS: at 58.63% examples, 1583137 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:08:30,213 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:30,217 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:30,217 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:30,219 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:30,220 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:30,221 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:30,224 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:30,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:30,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:30,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:30,229 : INFO : EPOCH - 1 : training on 2850148 raw words (2684139 effective words) took 1.6s, 1685781 effective words/s\n",
      "2019-09-14 17:08:31,239 : INFO : EPOCH 2 - PROGRESS: at 58.98% examples, 1596057 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-14 17:08:31,872 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:31,876 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:31,878 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:31,886 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:31,888 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:31,889 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:31,890 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:31,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:31,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:31,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:31,898 : INFO : EPOCH - 2 : training on 2850148 raw words (2683647 effective words) took 1.7s, 1615892 effective words/s\n",
      "2019-09-14 17:08:32,918 : INFO : EPOCH 3 - PROGRESS: at 57.16% examples, 1525480 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-14 17:08:33,587 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:33,603 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:33,606 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:33,607 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:33,608 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:33,609 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:33,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:33,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:33,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:33,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:33,623 : INFO : EPOCH - 3 : training on 2850148 raw words (2683321 effective words) took 1.7s, 1562719 effective words/s\n",
      "2019-09-14 17:08:34,636 : INFO : EPOCH 4 - PROGRESS: at 58.09% examples, 1564135 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:08:35,253 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:35,256 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:35,264 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:35,270 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:35,274 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:35,275 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:35,276 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:35,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:35,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:35,282 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:35,282 : INFO : EPOCH - 4 : training on 2850148 raw words (2683759 effective words) took 1.7s, 1626259 effective words/s\n",
      "2019-09-14 17:08:36,298 : INFO : EPOCH 5 - PROGRESS: at 61.11% examples, 1643609 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-14 17:08:36,870 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:36,871 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:36,872 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:36,875 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:36,878 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:36,879 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:36,884 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:36,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:36,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:36,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:36,887 : INFO : EPOCH - 5 : training on 2850148 raw words (2684376 effective words) took 1.6s, 1681914 effective words/s\n",
      "2019-09-14 17:08:36,887 : INFO : training on a 14250740 raw words (13419242 effective words) took 8.3s, 1624927 effective words/s\n",
      "2019-09-14 17:08:36,888 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 17:08:36,888 : INFO : training model with 10 workers on 215409 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 17:08:37,897 : INFO : EPOCH 1 - PROGRESS: at 58.61% examples, 1586830 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:08:38,514 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:38,521 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:38,526 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:08:38,532 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:38,535 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:38,537 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:38,538 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:38,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:38,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:38,546 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:38,547 : INFO : EPOCH - 1 : training on 2850148 raw words (2683704 effective words) took 1.7s, 1625955 effective words/s\n",
      "2019-09-14 17:08:39,563 : INFO : EPOCH 2 - PROGRESS: at 58.86% examples, 1577070 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:08:40,175 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:40,181 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:40,183 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:40,185 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:40,186 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:40,186 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:40,187 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:40,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:40,193 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:40,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:40,198 : INFO : EPOCH - 2 : training on 2850148 raw words (2684134 effective words) took 1.6s, 1633173 effective words/s\n",
      "2019-09-14 17:08:41,221 : INFO : EPOCH 3 - PROGRESS: at 58.15% examples, 1549816 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:08:41,831 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:41,833 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:41,834 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:41,835 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:41,836 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:41,846 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:41,847 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:41,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:41,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:41,852 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:41,852 : INFO : EPOCH - 3 : training on 2850148 raw words (2683684 effective words) took 1.6s, 1631047 effective words/s\n",
      "2019-09-14 17:08:42,865 : INFO : EPOCH 4 - PROGRESS: at 59.76% examples, 1609919 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-14 17:08:43,450 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:43,452 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:43,454 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:43,454 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:43,458 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:43,460 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:43,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:43,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:43,466 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:43,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:43,469 : INFO : EPOCH - 4 : training on 2850148 raw words (2683701 effective words) took 1.6s, 1668068 effective words/s\n",
      "2019-09-14 17:08:44,486 : INFO : EPOCH 5 - PROGRESS: at 58.09% examples, 1557102 words/s, in_qsize 18, out_qsize 2\n",
      "2019-09-14 17:08:45,121 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:45,124 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:45,126 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:45,136 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:45,137 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:45,138 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:45,138 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:45,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:45,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:45,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:45,143 : INFO : EPOCH - 5 : training on 2850148 raw words (2683415 effective words) took 1.7s, 1611458 effective words/s\n",
      "2019-09-14 17:08:46,154 : INFO : EPOCH 6 - PROGRESS: at 59.28% examples, 1604309 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:08:46,765 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:46,767 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:46,770 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:46,777 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:46,780 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:46,784 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:46,785 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:46,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:46,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:46,787 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:46,787 : INFO : EPOCH - 6 : training on 2850148 raw words (2683951 effective words) took 1.6s, 1640171 effective words/s\n",
      "2019-09-14 17:08:47,810 : INFO : EPOCH 7 - PROGRESS: at 59.46% examples, 1585836 words/s, in_qsize 17, out_qsize 3\n",
      "2019-09-14 17:08:48,385 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:48,391 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:48,394 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:48,395 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:48,396 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:48,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:48,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:48,402 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:48,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:48,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:48,404 : INFO : EPOCH - 7 : training on 2850148 raw words (2684141 effective words) took 1.6s, 1668678 effective words/s\n",
      "2019-09-14 17:08:49,415 : INFO : EPOCH 8 - PROGRESS: at 58.37% examples, 1575128 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:08:50,050 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:50,055 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:50,067 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:50,071 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:08:50,073 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:50,076 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:50,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:50,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:50,080 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:50,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:50,082 : INFO : EPOCH - 8 : training on 2850148 raw words (2683918 effective words) took 1.7s, 1607250 effective words/s\n",
      "2019-09-14 17:08:51,098 : INFO : EPOCH 9 - PROGRESS: at 58.37% examples, 1567759 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:08:51,726 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:51,733 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:51,739 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:51,741 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:51,746 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:51,749 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:51,750 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:51,752 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:51,752 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:51,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:51,753 : INFO : EPOCH - 9 : training on 2850148 raw words (2683367 effective words) took 1.7s, 1613604 effective words/s\n",
      "2019-09-14 17:08:52,770 : INFO : EPOCH 10 - PROGRESS: at 58.63% examples, 1577393 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:08:53,379 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:08:53,390 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:08:53,393 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:08:53,394 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:08:53,397 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:08:53,400 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:08:53,401 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:08:53,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:08:53,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:08:53,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:08:53,410 : INFO : EPOCH - 10 : training on 2850148 raw words (2683620 effective words) took 1.6s, 1628140 effective words/s\n",
      "2019-09-14 17:08:53,410 : INFO : training on a 28501480 raw words (26837635 effective words) took 16.5s, 1624324 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26837635, 28501480)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50 = gensim.models.Word2Vec (documents, size=50, window=5, min_count=1, workers=10)\n",
    "model_50.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summer', 0.598514199256897),\n",
       " ('shine', 0.5947161912918091),\n",
       " ('entertaining', 0.569084882736206),\n",
       " ('lovers', 0.5555052757263184),\n",
       " ('distraught', 0.549052357673645),\n",
       " ('lesbian', 0.5480132102966309),\n",
       " ('lunchbox', 0.5436629056930542),\n",
       " ('loves', 0.5386382937431335),\n",
       " ('macedonian', 0.5340943932533264),\n",
       " ('chilli', 0.533340573310852)]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dirty\"\n",
    "model_w10.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:06:17,359 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lonely', 0.6224201321601868),\n",
       " ('yea', 0.5781300663948059),\n",
       " ('rin', 0.56827312707901),\n",
       " ('kubeq', 0.560832142829895),\n",
       " ('selkyle', 0.5602914094924927),\n",
       " ('ichi', 0.5590268969535828),\n",
       " ('kurai', 0.5576327443122864),\n",
       " ('haus', 0.5574352741241455),\n",
       " ('hada', 0.556331217288971),\n",
       " ('lovable', 0.5562098026275635)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_350.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:07:55,439 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hilarious', 0.6041868925094604),\n",
       " ('bescheid', 0.6005462408065796),\n",
       " ('powdery', 0.5853187441825867),\n",
       " ('vart', 0.5842375755310059),\n",
       " ('sounding', 0.5832367539405823),\n",
       " ('impressive', 0.5798879861831665),\n",
       " ('loggat', 0.5757322907447815),\n",
       " ('bred', 0.5708400011062622),\n",
       " ('odor', 0.5691222548484802),\n",
       " ('acceptance', 0.5686191916465759)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_250.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:08:53,416 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('absolutely', 0.6712888479232788),\n",
       " ('rich', 0.6527135372161865),\n",
       " ('idk', 0.6500565409660339),\n",
       " ('sometimes', 0.6492269039154053),\n",
       " ('workclothes', 0.6474051475524902),\n",
       " ('tonight', 0.6447423696517944),\n",
       " ('fucking', 0.6414129734039307),\n",
       " ('gay', 0.6371513605117798),\n",
       " ('alright', 0.6371066570281982),\n",
       " ('lucian', 0.636875569820404)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:17:31,410 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 17:17:31,411 : INFO : collecting all words and their counts\n",
      "2019-09-14 17:17:31,411 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 17:17:31,418 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 17:17:31,426 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 17:17:31,434 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 17:17:31,442 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 17:17:31,450 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 17:17:31,457 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 17:17:31,464 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 17:17:31,472 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 17:17:31,480 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 17:17:31,487 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 17:17:31,494 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 17:17:31,501 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 17:17:31,508 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 17:17:31,515 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 17:17:31,522 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 17:17:31,529 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 17:17:31,537 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 17:17:31,543 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 17:17:31,551 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 17:17:31,559 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 17:17:31,567 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 17:17:31,577 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 17:17:31,584 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 17:17:31,591 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 17:17:31,598 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 17:17:31,605 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 17:17:31,612 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 17:17:31,620 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 17:17:31,628 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 17:17:31,635 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 17:17:31,644 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 17:17:31,653 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 17:17:31,661 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 17:17:31,668 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 17:17:31,677 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 17:17:31,685 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 17:17:31,692 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 17:17:31,701 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 17:17:31,709 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 17:17:31,717 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 17:17:31,724 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 17:17:31,732 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 17:17:31,740 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 17:17:31,748 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 17:17:31,757 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 17:17:31,765 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 17:17:31,773 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 17:17:31,782 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 17:17:31,790 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 17:17:31,798 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 17:17:31,805 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 17:17:31,813 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 17:17:31,821 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 17:17:31,829 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 17:17:31,837 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 17:17:31,844 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 17:17:31,855 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 17:17:31,864 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 17:17:31,871 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 17:17:31,879 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 17:17:31,886 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 17:17:31,893 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 17:17:31,900 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 17:17:31,908 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 17:17:31,915 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 17:17:31,922 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 17:17:31,930 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 17:17:31,937 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 17:17:31,944 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 17:17:31,952 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:17:31,959 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 17:17:31,966 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 17:17:31,973 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 17:17:31,980 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 17:17:31,990 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 17:17:31,998 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 17:17:32,004 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 17:17:32,005 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 17:17:32,333 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 17:17:32,334 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 17:17:32,860 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 17:17:32,863 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 17:17:32,864 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 17:17:33,387 : INFO : estimated required memory for 215409 words and 150 dimensions: 366195300 bytes\n",
      "2019-09-14 17:17:33,388 : INFO : resetting layer weights\n",
      "2019-09-14 17:17:35,077 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=30\n",
      "2019-09-14 17:17:36,097 : INFO : EPOCH 1 - PROGRESS: at 51.08% examples, 1369031 words/s, in_qsize 16, out_qsize 4\n",
      "2019-09-14 17:17:36,917 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:36,918 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:36,923 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:36,934 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:36,935 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:36,936 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:36,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:36,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:36,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:36,940 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:36,940 : INFO : EPOCH - 1 : training on 2850148 raw words (2683605 effective words) took 1.9s, 1448091 effective words/s\n",
      "2019-09-14 17:17:37,958 : INFO : EPOCH 2 - PROGRESS: at 54.02% examples, 1445728 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:38,715 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:38,716 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:38,717 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:38,722 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:38,727 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:38,729 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:38,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:38,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:38,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:38,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:38,739 : INFO : EPOCH - 2 : training on 2850148 raw words (2683549 effective words) took 1.8s, 1498555 effective words/s\n",
      "2019-09-14 17:17:39,748 : INFO : EPOCH 3 - PROGRESS: at 54.95% examples, 1485034 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:40,477 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:40,486 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:40,487 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:40,491 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:40,496 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:40,499 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:40,501 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:40,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:40,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:40,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:40,510 : INFO : EPOCH - 3 : training on 2850148 raw words (2683733 effective words) took 1.8s, 1522262 effective words/s\n",
      "2019-09-14 17:17:41,534 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 1306619 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:17:42,442 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:42,443 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:42,448 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:42,448 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:42,450 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:42,453 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:42,459 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:42,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:42,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:42,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:42,469 : INFO : EPOCH - 4 : training on 2850148 raw words (2683952 effective words) took 2.0s, 1376250 effective words/s\n",
      "2019-09-14 17:17:43,491 : INFO : EPOCH 5 - PROGRESS: at 52.54% examples, 1400834 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-14 17:17:44,247 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:44,252 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:44,264 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:44,266 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:44,267 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:44,269 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:44,273 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:44,275 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:44,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:44,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:44,278 : INFO : EPOCH - 5 : training on 2850148 raw words (2683764 effective words) took 1.8s, 1490129 effective words/s\n",
      "2019-09-14 17:17:44,278 : INFO : training on a 14250740 raw words (13418603 effective words) took 9.2s, 1458618 effective words/s\n",
      "2019-09-14 17:17:44,279 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 17:17:44,279 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=30\n",
      "2019-09-14 17:17:45,300 : INFO : EPOCH 1 - PROGRESS: at 54.39% examples, 1449513 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:17:46,055 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:46,060 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:46,062 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:17:46,067 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:46,070 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:46,073 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:46,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:46,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:46,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:46,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:46,089 : INFO : EPOCH - 1 : training on 2850148 raw words (2683513 effective words) took 1.8s, 1488969 effective words/s\n",
      "2019-09-14 17:17:47,138 : INFO : EPOCH 2 - PROGRESS: at 54.73% examples, 1420330 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:47,840 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:47,841 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:47,849 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:47,853 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:47,857 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:47,859 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:47,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:47,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:47,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:47,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:47,863 : INFO : EPOCH - 2 : training on 2850148 raw words (2683654 effective words) took 1.8s, 1519726 effective words/s\n",
      "2019-09-14 17:17:48,874 : INFO : EPOCH 3 - PROGRESS: at 54.27% examples, 1462601 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:49,595 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:49,598 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:49,606 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:49,607 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:49,611 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:49,612 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:49,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:49,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:49,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:49,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:49,622 : INFO : EPOCH - 3 : training on 2850148 raw words (2683501 effective words) took 1.8s, 1532902 effective words/s\n",
      "2019-09-14 17:17:50,632 : INFO : EPOCH 4 - PROGRESS: at 48.43% examples, 1304429 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:51,496 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:51,508 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:51,516 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:51,519 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:51,520 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:51,520 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:51,522 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:51,524 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:51,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:51,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:51,532 : INFO : EPOCH - 4 : training on 2850148 raw words (2683987 effective words) took 1.9s, 1411158 effective words/s\n",
      "2019-09-14 17:17:52,548 : INFO : EPOCH 5 - PROGRESS: at 52.53% examples, 1410068 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:17:53,419 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:53,421 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:53,425 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:53,429 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:53,430 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:53,432 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:53,433 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:53,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:53,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:53,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:53,436 : INFO : EPOCH - 5 : training on 2850148 raw words (2683732 effective words) took 1.9s, 1415914 effective words/s\n",
      "2019-09-14 17:17:54,450 : INFO : EPOCH 6 - PROGRESS: at 51.41% examples, 1384530 words/s, in_qsize 16, out_qsize 1\n",
      "2019-09-14 17:17:55,230 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:55,235 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:55,238 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:55,241 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:55,248 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:55,255 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:55,257 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:55,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:55,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:55,276 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:55,277 : INFO : EPOCH - 6 : training on 2850148 raw words (2684138 effective words) took 1.8s, 1464991 effective words/s\n",
      "2019-09-14 17:17:56,287 : INFO : EPOCH 7 - PROGRESS: at 53.25% examples, 1436160 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:17:57,017 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:57,019 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:57,030 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:57,032 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:17:57,036 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:57,037 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:57,038 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:57,042 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:57,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:57,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:57,044 : INFO : EPOCH - 7 : training on 2850148 raw words (2683608 effective words) took 1.8s, 1525514 effective words/s\n",
      "2019-09-14 17:17:58,074 : INFO : EPOCH 8 - PROGRESS: at 55.62% examples, 1471532 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:17:58,750 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:17:58,751 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:17:58,752 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:17:58,752 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:17:58,764 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:17:58,768 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:17:58,768 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:17:58,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:17:58,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:17:58,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:17:58,786 : INFO : EPOCH - 8 : training on 2850148 raw words (2683910 effective words) took 1.7s, 1547741 effective words/s\n",
      "2019-09-14 17:17:59,800 : INFO : EPOCH 9 - PROGRESS: at 55.33% examples, 1486673 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:18:00,508 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:18:00,514 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:18:00,520 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:18:00,520 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:18:00,527 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:18:00,529 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:18:00,537 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:18:00,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:18:00,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:18:00,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:18:00,540 : INFO : EPOCH - 9 : training on 2850148 raw words (2684305 effective words) took 1.7s, 1537608 effective words/s\n",
      "2019-09-14 17:18:01,551 : INFO : EPOCH 10 - PROGRESS: at 54.30% examples, 1463343 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:18:02,265 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:18:02,269 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:18:02,271 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:18:02,282 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:18:02,284 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:18:02,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:18:02,287 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:18:02,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:18:02,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:18:02,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:18:02,295 : INFO : EPOCH - 10 : training on 2850148 raw words (2683981 effective words) took 1.7s, 1536506 effective words/s\n",
      "2019-09-14 17:18:02,295 : INFO : training on a 28501480 raw words (26838329 effective words) took 18.0s, 1489723 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26838329, 28501480)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w30 = gensim.models.Word2Vec (documents, size=150, window=30, min_count=1, workers=10)\n",
    "model_w30.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:22:40,361 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 17:22:40,362 : INFO : collecting all words and their counts\n",
      "2019-09-14 17:22:40,362 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 17:22:40,369 : INFO : PROGRESS: at sentence #10000, processed 35336 words, keeping 7703 word types\n",
      "2019-09-14 17:22:40,377 : INFO : PROGRESS: at sentence #20000, processed 81667 words, keeping 14883 word types\n",
      "2019-09-14 17:22:40,385 : INFO : PROGRESS: at sentence #30000, processed 126818 words, keeping 20346 word types\n",
      "2019-09-14 17:22:40,393 : INFO : PROGRESS: at sentence #40000, processed 166449 words, keeping 24392 word types\n",
      "2019-09-14 17:22:40,400 : INFO : PROGRESS: at sentence #50000, processed 203483 words, keeping 28720 word types\n",
      "2019-09-14 17:22:40,407 : INFO : PROGRESS: at sentence #60000, processed 238327 words, keeping 34046 word types\n",
      "2019-09-14 17:22:40,414 : INFO : PROGRESS: at sentence #70000, processed 269432 words, keeping 38486 word types\n",
      "2019-09-14 17:22:40,421 : INFO : PROGRESS: at sentence #80000, processed 305370 words, keeping 42131 word types\n",
      "2019-09-14 17:22:40,429 : INFO : PROGRESS: at sentence #90000, processed 346139 words, keeping 46205 word types\n",
      "2019-09-14 17:22:40,436 : INFO : PROGRESS: at sentence #100000, processed 380464 words, keeping 49475 word types\n",
      "2019-09-14 17:22:40,443 : INFO : PROGRESS: at sentence #110000, processed 411780 words, keeping 53973 word types\n",
      "2019-09-14 17:22:40,450 : INFO : PROGRESS: at sentence #120000, processed 445715 words, keeping 59637 word types\n",
      "2019-09-14 17:22:40,457 : INFO : PROGRESS: at sentence #130000, processed 480413 words, keeping 62826 word types\n",
      "2019-09-14 17:22:40,464 : INFO : PROGRESS: at sentence #140000, processed 513300 words, keeping 65162 word types\n",
      "2019-09-14 17:22:40,471 : INFO : PROGRESS: at sentence #150000, processed 546460 words, keeping 67588 word types\n",
      "2019-09-14 17:22:40,478 : INFO : PROGRESS: at sentence #160000, processed 583265 words, keeping 70515 word types\n",
      "2019-09-14 17:22:40,485 : INFO : PROGRESS: at sentence #170000, processed 622209 words, keeping 73552 word types\n",
      "2019-09-14 17:22:40,493 : INFO : PROGRESS: at sentence #180000, processed 655958 words, keeping 76592 word types\n",
      "2019-09-14 17:22:40,500 : INFO : PROGRESS: at sentence #190000, processed 694393 words, keeping 79380 word types\n",
      "2019-09-14 17:22:40,508 : INFO : PROGRESS: at sentence #200000, processed 733733 words, keeping 83053 word types\n",
      "2019-09-14 17:22:40,516 : INFO : PROGRESS: at sentence #210000, processed 775168 words, keeping 86193 word types\n",
      "2019-09-14 17:22:40,525 : INFO : PROGRESS: at sentence #220000, processed 814139 words, keeping 89597 word types\n",
      "2019-09-14 17:22:40,532 : INFO : PROGRESS: at sentence #230000, processed 849446 words, keeping 92239 word types\n",
      "2019-09-14 17:22:40,539 : INFO : PROGRESS: at sentence #240000, processed 883789 words, keeping 95632 word types\n",
      "2019-09-14 17:22:40,546 : INFO : PROGRESS: at sentence #250000, processed 919643 words, keeping 98297 word types\n",
      "2019-09-14 17:22:40,553 : INFO : PROGRESS: at sentence #260000, processed 952853 words, keeping 100594 word types\n",
      "2019-09-14 17:22:40,559 : INFO : PROGRESS: at sentence #270000, processed 985436 words, keeping 103935 word types\n",
      "2019-09-14 17:22:40,567 : INFO : PROGRESS: at sentence #280000, processed 1026896 words, keeping 106990 word types\n",
      "2019-09-14 17:22:40,574 : INFO : PROGRESS: at sentence #290000, processed 1067748 words, keeping 109770 word types\n",
      "2019-09-14 17:22:40,582 : INFO : PROGRESS: at sentence #300000, processed 1108087 words, keeping 111931 word types\n",
      "2019-09-14 17:22:40,589 : INFO : PROGRESS: at sentence #310000, processed 1141930 words, keeping 114664 word types\n",
      "2019-09-14 17:22:40,597 : INFO : PROGRESS: at sentence #320000, processed 1185000 words, keeping 117180 word types\n",
      "2019-09-14 17:22:40,605 : INFO : PROGRESS: at sentence #330000, processed 1227030 words, keeping 119706 word types\n",
      "2019-09-14 17:22:40,612 : INFO : PROGRESS: at sentence #340000, processed 1261627 words, keeping 121897 word types\n",
      "2019-09-14 17:22:40,621 : INFO : PROGRESS: at sentence #350000, processed 1305224 words, keeping 124253 word types\n",
      "2019-09-14 17:22:40,628 : INFO : PROGRESS: at sentence #360000, processed 1342987 words, keeping 126139 word types\n",
      "2019-09-14 17:22:40,636 : INFO : PROGRESS: at sentence #370000, processed 1379942 words, keeping 128747 word types\n",
      "2019-09-14 17:22:40,644 : INFO : PROGRESS: at sentence #380000, processed 1420941 words, keeping 131097 word types\n",
      "2019-09-14 17:22:40,652 : INFO : PROGRESS: at sentence #390000, processed 1462200 words, keeping 134453 word types\n",
      "2019-09-14 17:22:40,659 : INFO : PROGRESS: at sentence #400000, processed 1498221 words, keeping 136674 word types\n",
      "2019-09-14 17:22:40,666 : INFO : PROGRESS: at sentence #410000, processed 1532526 words, keeping 138647 word types\n",
      "2019-09-14 17:22:40,674 : INFO : PROGRESS: at sentence #420000, processed 1570525 words, keeping 141751 word types\n",
      "2019-09-14 17:22:40,682 : INFO : PROGRESS: at sentence #430000, processed 1606919 words, keeping 143912 word types\n",
      "2019-09-14 17:22:40,689 : INFO : PROGRESS: at sentence #440000, processed 1643851 words, keeping 146431 word types\n",
      "2019-09-14 17:22:40,697 : INFO : PROGRESS: at sentence #450000, processed 1684709 words, keeping 149176 word types\n",
      "2019-09-14 17:22:40,705 : INFO : PROGRESS: at sentence #460000, processed 1723056 words, keeping 151311 word types\n",
      "2019-09-14 17:22:40,713 : INFO : PROGRESS: at sentence #470000, processed 1764754 words, keeping 155055 word types\n",
      "2019-09-14 17:22:40,721 : INFO : PROGRESS: at sentence #480000, processed 1805467 words, keeping 156732 word types\n",
      "2019-09-14 17:22:40,728 : INFO : PROGRESS: at sentence #490000, processed 1841467 words, keeping 158936 word types\n",
      "2019-09-14 17:22:40,736 : INFO : PROGRESS: at sentence #500000, processed 1881299 words, keeping 160981 word types\n",
      "2019-09-14 17:22:40,743 : INFO : PROGRESS: at sentence #510000, processed 1910757 words, keeping 162726 word types\n",
      "2019-09-14 17:22:40,751 : INFO : PROGRESS: at sentence #520000, processed 1951324 words, keeping 165921 word types\n",
      "2019-09-14 17:22:40,758 : INFO : PROGRESS: at sentence #530000, processed 1984460 words, keeping 168046 word types\n",
      "2019-09-14 17:22:40,765 : INFO : PROGRESS: at sentence #540000, processed 2021693 words, keeping 170872 word types\n",
      "2019-09-14 17:22:40,773 : INFO : PROGRESS: at sentence #550000, processed 2059107 words, keeping 172897 word types\n",
      "2019-09-14 17:22:40,780 : INFO : PROGRESS: at sentence #560000, processed 2091731 words, keeping 174608 word types\n",
      "2019-09-14 17:22:40,791 : INFO : PROGRESS: at sentence #570000, processed 2128039 words, keeping 176663 word types\n",
      "2019-09-14 17:22:40,799 : INFO : PROGRESS: at sentence #580000, processed 2166392 words, keeping 179237 word types\n",
      "2019-09-14 17:22:40,807 : INFO : PROGRESS: at sentence #590000, processed 2201985 words, keeping 181165 word types\n",
      "2019-09-14 17:22:40,814 : INFO : PROGRESS: at sentence #600000, processed 2242568 words, keeping 183012 word types\n",
      "2019-09-14 17:22:40,822 : INFO : PROGRESS: at sentence #610000, processed 2275539 words, keeping 185470 word types\n",
      "2019-09-14 17:22:40,829 : INFO : PROGRESS: at sentence #620000, processed 2309476 words, keeping 187652 word types\n",
      "2019-09-14 17:22:40,836 : INFO : PROGRESS: at sentence #630000, processed 2346398 words, keeping 189720 word types\n",
      "2019-09-14 17:22:40,844 : INFO : PROGRESS: at sentence #640000, processed 2382215 words, keeping 191872 word types\n",
      "2019-09-14 17:22:40,851 : INFO : PROGRESS: at sentence #650000, processed 2420323 words, keeping 193857 word types\n",
      "2019-09-14 17:22:40,858 : INFO : PROGRESS: at sentence #660000, processed 2452875 words, keeping 195743 word types\n",
      "2019-09-14 17:22:40,867 : INFO : PROGRESS: at sentence #670000, processed 2498793 words, keeping 197857 word types\n",
      "2019-09-14 17:22:40,875 : INFO : PROGRESS: at sentence #680000, processed 2533698 words, keeping 200100 word types\n",
      "2019-09-14 17:22:40,882 : INFO : PROGRESS: at sentence #690000, processed 2568759 words, keeping 201832 word types\n",
      "2019-09-14 17:22:40,890 : INFO : PROGRESS: at sentence #700000, processed 2607438 words, keeping 203675 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:22:40,897 : INFO : PROGRESS: at sentence #710000, processed 2642447 words, keeping 205688 word types\n",
      "2019-09-14 17:22:40,905 : INFO : PROGRESS: at sentence #720000, processed 2679221 words, keeping 207750 word types\n",
      "2019-09-14 17:22:40,912 : INFO : PROGRESS: at sentence #730000, processed 2713908 words, keeping 209261 word types\n",
      "2019-09-14 17:22:40,919 : INFO : PROGRESS: at sentence #740000, processed 2746275 words, keeping 210737 word types\n",
      "2019-09-14 17:22:40,926 : INFO : PROGRESS: at sentence #750000, processed 2777743 words, keeping 212385 word types\n",
      "2019-09-14 17:22:40,934 : INFO : PROGRESS: at sentence #760000, processed 2813979 words, keeping 214510 word types\n",
      "2019-09-14 17:22:40,940 : INFO : collected 215409 word types from a corpus of 2850148 raw words and 766508 sentences\n",
      "2019-09-14 17:22:40,940 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 17:22:41,564 : INFO : effective_min_count=1 retains 215409 unique words (100% of original 215409, drops 0)\n",
      "2019-09-14 17:22:41,565 : INFO : effective_min_count=1 leaves 2850148 word corpus (100% of original 2850148, drops 0)\n",
      "2019-09-14 17:22:42,080 : INFO : deleting the raw counts dictionary of 215409 items\n",
      "2019-09-14 17:22:42,084 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2019-09-14 17:22:42,084 : INFO : downsampling leaves estimated 2683831 word corpus (94.2% of prior 2850148)\n",
      "2019-09-14 17:22:42,572 : INFO : estimated required memory for 215409 words and 150 dimensions: 366195300 bytes\n",
      "2019-09-14 17:22:42,573 : INFO : resetting layer weights\n",
      "2019-09-14 17:22:44,276 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-14 17:22:45,292 : INFO : EPOCH 1 - PROGRESS: at 55.86% examples, 1494382 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:46,079 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:46,082 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:46,083 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:46,083 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:46,084 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:46,093 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:46,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:46,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:46,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:46,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:46,101 : INFO : EPOCH - 1 : training on 2850148 raw words (2683943 effective words) took 1.8s, 1477506 effective words/s\n",
      "2019-09-14 17:22:47,139 : INFO : EPOCH 2 - PROGRESS: at 55.95% examples, 1471885 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:47,810 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:47,815 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:47,815 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:47,824 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:47,828 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:47,829 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:47,830 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:47,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:47,832 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:47,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:47,834 : INFO : EPOCH - 2 : training on 2850148 raw words (2683997 effective words) took 1.7s, 1556802 effective words/s\n",
      "2019-09-14 17:22:48,851 : INFO : EPOCH 3 - PROGRESS: at 55.34% examples, 1482574 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:22:49,535 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:49,545 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:49,547 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:49,548 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:49,557 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:49,558 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:49,562 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:49,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:49,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:49,576 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:49,576 : INFO : EPOCH - 3 : training on 2850148 raw words (2684099 effective words) took 1.7s, 1547608 effective words/s\n",
      "2019-09-14 17:22:50,586 : INFO : EPOCH 4 - PROGRESS: at 55.83% examples, 1504554 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:51,259 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:51,265 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:51,269 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:51,273 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:51,274 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:51,274 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:51,275 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:51,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:51,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:51,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:51,279 : INFO : EPOCH - 4 : training on 2850148 raw words (2683646 effective words) took 1.7s, 1583850 effective words/s\n",
      "2019-09-14 17:22:52,310 : INFO : EPOCH 5 - PROGRESS: at 53.48% examples, 1415017 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:22:53,019 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:53,021 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:53,026 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:53,032 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:53,033 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:53,036 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:53,037 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:53,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:53,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:53,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:53,047 : INFO : EPOCH - 5 : training on 2850148 raw words (2683957 effective words) took 1.8s, 1525249 effective words/s\n",
      "2019-09-14 17:22:53,047 : INFO : training on a 14250740 raw words (13419642 effective words) took 8.8s, 1530142 effective words/s\n",
      "2019-09-14 17:22:53,048 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 17:22:53,048 : INFO : training model with 10 workers on 215409 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-14 17:22:54,056 : INFO : EPOCH 1 - PROGRESS: at 56.46% examples, 1523191 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:54,739 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:54,750 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:54,752 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:22:54,754 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:54,758 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:54,763 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:54,764 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:54,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:54,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:54,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:54,768 : INFO : EPOCH - 1 : training on 2850148 raw words (2683523 effective words) took 1.7s, 1567300 effective words/s\n",
      "2019-09-14 17:22:55,780 : INFO : EPOCH 2 - PROGRESS: at 55.62% examples, 1498518 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:56,449 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:56,452 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:56,454 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:56,461 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:56,463 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:56,464 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:56,467 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:56,469 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:56,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:56,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:56,476 : INFO : EPOCH - 2 : training on 2850148 raw words (2683901 effective words) took 1.7s, 1579101 effective words/s\n",
      "2019-09-14 17:22:57,489 : INFO : EPOCH 3 - PROGRESS: at 50.75% examples, 1366176 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:58,267 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:58,275 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:58,280 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:58,284 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:58,288 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:58,291 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:58,291 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:58,292 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:58,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:58,295 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:58,295 : INFO : EPOCH - 3 : training on 2850148 raw words (2684249 effective words) took 1.8s, 1481864 effective words/s\n",
      "2019-09-14 17:22:59,311 : INFO : EPOCH 4 - PROGRESS: at 57.49% examples, 1539118 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:22:59,965 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:22:59,966 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:22:59,968 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:22:59,969 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:22:59,970 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:22:59,971 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:22:59,976 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:22:59,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:22:59,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:22:59,982 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:22:59,982 : INFO : EPOCH - 4 : training on 2850148 raw words (2683685 effective words) took 1.7s, 1598116 effective words/s\n",
      "2019-09-14 17:23:00,994 : INFO : EPOCH 5 - PROGRESS: at 57.16% examples, 1537172 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-14 17:23:01,681 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:01,683 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:01,684 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:01,685 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:23:01,691 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:01,695 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:01,696 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:01,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:01,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:01,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:01,700 : INFO : EPOCH - 5 : training on 2850148 raw words (2683540 effective words) took 1.7s, 1569774 effective words/s\n",
      "2019-09-14 17:23:02,710 : INFO : EPOCH 6 - PROGRESS: at 55.37% examples, 1494090 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-14 17:23:03,377 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:03,383 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:03,388 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:03,390 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:23:03,396 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:03,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:03,399 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:03,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:03,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:03,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:03,406 : INFO : EPOCH - 6 : training on 2850148 raw words (2684107 effective words) took 1.7s, 1580543 effective words/s\n",
      "2019-09-14 17:23:04,419 : INFO : EPOCH 7 - PROGRESS: at 56.55% examples, 1517072 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:23:05,077 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:05,093 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:05,094 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:05,095 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:23:05,095 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:05,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:05,097 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:05,100 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:05,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:05,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:05,101 : INFO : EPOCH - 7 : training on 2850148 raw words (2683579 effective words) took 1.7s, 1591252 effective words/s\n",
      "2019-09-14 17:23:06,123 : INFO : EPOCH 8 - PROGRESS: at 56.82% examples, 1511602 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:23:06,753 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:06,760 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:06,762 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:06,763 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:23:06,770 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:06,771 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:06,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:06,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:06,775 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:06,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:06,782 : INFO : EPOCH - 8 : training on 2850148 raw words (2683476 effective words) took 1.7s, 1603832 effective words/s\n",
      "2019-09-14 17:23:07,792 : INFO : EPOCH 9 - PROGRESS: at 57.81% examples, 1558263 words/s, in_qsize 18, out_qsize 0\n",
      "2019-09-14 17:23:08,413 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:08,419 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:08,421 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:08,430 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:23:08,433 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:08,434 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:08,434 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:08,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:08,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:08,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:08,440 : INFO : EPOCH - 9 : training on 2850148 raw words (2684268 effective words) took 1.7s, 1626748 effective words/s\n",
      "2019-09-14 17:23:09,457 : INFO : EPOCH 10 - PROGRESS: at 52.85% examples, 1417442 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-14 17:23:10,248 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 17:23:10,250 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 17:23:10,257 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 17:23:10,260 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 17:23:10,265 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 17:23:10,267 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 17:23:10,271 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 17:23:10,273 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 17:23:10,273 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 17:23:10,275 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 17:23:10,276 : INFO : EPOCH - 10 : training on 2850148 raw words (2683817 effective words) took 1.8s, 1468627 effective words/s\n",
      "2019-09-14 17:23:10,276 : INFO : training on a 28501480 raw words (26838145 effective words) took 17.2s, 1557842 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26838145, 28501480)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w10 = gensim.models.Word2Vec (documents, size=150, window=10, min_count=1, workers=10)\n",
    "model_w10.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:18:02,301 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lubeless', 0.5587435364723206),\n",
       " ('retard', 0.5531840324401855),\n",
       " ('calm', 0.534084677696228),\n",
       " ('mason', 0.5227146148681641),\n",
       " ('feminine', 0.5135031938552856),\n",
       " ('mimic', 0.5090172290802002),\n",
       " ('scumbag', 0.5058559775352478),\n",
       " ('upstage', 0.5042057037353516),\n",
       " ('lame', 0.5012328028678894),\n",
       " ('set_preferences', 0.49891215562820435)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w30.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 17:25:25,205 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('renderotica', 0.5119533538818359),\n",
       " ('add_file', 0.5112224221229553),\n",
       " ('workclothes', 0.4656129479408264),\n",
       " ('seriously', 0.46353253722190857),\n",
       " ('mason', 0.45548906922340393),\n",
       " ('tolerance', 0.4518297612667084),\n",
       " ('hada', 0.45053890347480774),\n",
       " ('jiong', 0.449445515871048),\n",
       " ('ichi', 0.4482629895210266),\n",
       " ('pulchritudinous', 0.4466547966003418)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w10.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18468846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#print(model[\"dirty\"])\n",
    "print(model.similarity('this', 'is'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonder', 0.5567528009414673),\n",
       " ('summer', 0.5425893664360046),\n",
       " ('twilight', 0.5404902696609497),\n",
       " ('bunny', 0.5233567357063293),\n",
       " ('kid', 0.5134377479553223),\n",
       " ('teenager', 0.4938942790031433)]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"dirty\"]\n",
    "model.wv.most_similar(positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lonely', 0.8134220242500305),\n",
       " ('njemjeckij', 0.7894322872161865),\n",
       " ('scheint', 0.7692892551422119),\n",
       " ('dreglar', 0.7665601968765259),\n",
       " ('dałi', 0.7655606269836426),\n",
       " ('minskar', 0.7644549012184143)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=w1,topn=6) #using the multiplicative combination objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3542429\n",
      "[('automatically', 0.5599952936172485), ('slot', 0.5406605005264282)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jupyter/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print (model.similarity('page', 'book'))\n",
    "print (model.most_similar(positive=['machine'], topn=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lyrical', 0.47744208574295044),\n",
       " ('linket', 0.4585130512714386),\n",
       " ('jayasindoor', 0.45342352986335754),\n",
       " ('rudramadevi', 0.44707661867141724),\n",
       " ('charlie', 0.4426744282245636),\n",
       " ('madanapalle', 0.43868982791900635),\n",
       " ('entertainments', 0.4371229112148285),\n",
       " ('internetes', 0.43119490146636963),\n",
       " ('textlabel', 0.4262203574180603),\n",
       " ('keaton', 0.4219883978366852)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = ['king']\n",
    "w2 = ['man']\n",
    "model.wv.most_similar(positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prodigy'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"marvel\",\"miracle\",\"wonder\",\"prodigy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "b=[3,4,5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158007\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "word_list=[]\n",
    "for file in glob.glob(\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*\"):\n",
    "    with open(file, 'rb') as f: \n",
    "        for line in f: \n",
    "            word_list+=gensim.utils.simple_preprocess(line)\n",
    "        word_list+=[\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\"]\n",
    "    #i+=1\n",
    "    #if i==1000: break\n",
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bml',\n",
       "  'cpp',\n",
       "  'defines',\n",
       "  'the',\n",
       "  'entry',\n",
       "  'point',\n",
       "  'for',\n",
       "  'the',\n",
       "  'console',\n",
       "  'application'],\n",
       " [],\n",
       " [],\n",
       " ['include', 'stdafx'],\n",
       " ['include', 'iostream'],\n",
       " ['include', 'time'],\n",
       " ['include', 'windows'],\n",
       " ['include', 'math'],\n",
       " ['include', 'cstdlib'],\n",
       " ['using', 'namespace', 'std'],\n",
       " ['int', 'matrixsize'],\n",
       " ['bool', 'ischecked'],\n",
       " ['int', 'probability', 'procentach'],\n",
       " [],\n",
       " ['int', 'main'],\n",
       " [],\n",
       " ['bool', 'checkede', 'false'],\n",
       " ['bool', 'checkedn', 'false'],\n",
       " ['bool', 'tick', 'false'],\n",
       " ['generujemy', 'tablice'],\n",
       " ['int', 'matrix', 'new', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['matrix', 'new', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['generujemy', 'tablice', 'pomocnicza'],\n",
       " ['int', 'matrix', 'new', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " [],\n",
       " ['matrix', 'new', 'int', 'matrixsize'],\n",
       " [],\n",
       " [],\n",
       " ['wypelniamy', 'glowna', 'tablice', 'zerami'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " ['wypelniamy', 'macierz', 'pomocnicza', 'zerami'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['int', 'probability', 'floor', 'probability'],\n",
       " [],\n",
       " ['srand', 'time', 'null'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " ['int'],\n",
       " [],\n",
       " ['generowanie', 'pojazdow'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['cout', 'endl'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrixsize'],\n",
       " [],\n",
       " [],\n",
       " ['int',\n",
       "  'rand',\n",
       "  'losujemy',\n",
       "  'czy',\n",
       "  'dane',\n",
       "  'pole',\n",
       "  'bedzie',\n",
       "  'puste',\n",
       "  'czy',\n",
       "  'nie'],\n",
       " ['if',\n",
       "  'probability',\n",
       "  'jesli',\n",
       "  'polu',\n",
       "  'ma',\n",
       "  'byc',\n",
       "  'wygenerowany',\n",
       "  'samochod'],\n",
       " [],\n",
       " [],\n",
       " ['int', 'rand', 'losowanie', 'jaki', 'pojazd', 'zostanie', 'przypisany'],\n",
       " ['if',\n",
       "  'jesli',\n",
       "  'to',\n",
       "  'samochod',\n",
       "  'przesuwa',\n",
       "  'sie',\n",
       "  'gore',\n",
       "  'jesli',\n",
       "  'to',\n",
       "  'prawo'],\n",
       " [],\n",
       " ['if', 'matrix', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " ['if', 'jesli', 'to', 'samochod', 'przesuwa', 'sie', 'prawo'],\n",
       " [],\n",
       " ['if', 'matrix', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix', 'puste', 'pole'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['while'],\n",
       " [],\n",
       " ['wyswietlanie', 'samochodow'],\n",
       " ['system', 'cls'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['cout', 'puste', 'pole'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'gore'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'prawo'],\n",
       " [],\n",
       " [],\n",
       " ['cout', 'endl'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['przesuwanie', 'pojazdow'],\n",
       " ['if',\n",
       "  'tick',\n",
       "  'false',\n",
       "  'tym',\n",
       "  'przypadku',\n",
       "  'ruszaja',\n",
       "  'sie',\n",
       "  'samochody',\n",
       "  'idace',\n",
       "  'prawo'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['int'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['if',\n",
       "  'tick',\n",
       "  'true',\n",
       "  'tutaj',\n",
       "  'przesuwaja',\n",
       "  'sie',\n",
       "  'samochodu',\n",
       "  'poruszajace',\n",
       "  'sie',\n",
       "  'gore'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['int'],\n",
       " ['if', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " ['else'],\n",
       " [],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['tick', 'tick'],\n",
       " ['tick',\n",
       "  'tick',\n",
       "  'zmieniamy',\n",
       "  'rodzaj',\n",
       "  'samochodow',\n",
       "  'ktore',\n",
       "  'beda',\n",
       "  'przesuwane',\n",
       "  'nastepnej',\n",
       "  'iteracji'],\n",
       " [],\n",
       " ['test', 'wyswietlania'],\n",
       " ['cout', 'endl'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['if', 'matrix'],\n",
       " [],\n",
       " ['cout', 'puste', 'pole'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'gore'],\n",
       " [],\n",
       " ['else', 'if', 'matrix', 'matrix'],\n",
       " [],\n",
       " ['cout', 'samochod', 'poruszajacy', 'sie', 'prawo'],\n",
       " [],\n",
       " [],\n",
       " ['cout', 'endl'],\n",
       " [],\n",
       " ['sleep'],\n",
       " [],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix', 'matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['zerujemy', 'macierz', 'pomocnicza'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['for', 'int', 'matrixsize'],\n",
       " ['matrix'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['sleep'],\n",
       " [],\n",
       " ['system', 'pause'],\n",
       " ['return'],\n",
       " [],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['using', 'system', 'collections'],\n",
       " ['using', 'system', 'collections', 'generic'],\n",
       " ['using', 'unityengine'],\n",
       " [],\n",
       " ['enum', 'tile', 'plains', 'desert', 'mountain', 'forest'],\n",
       " ['enum', 'resource', 'wood', 'stone', 'fruit'],\n",
       " [],\n",
       " ['public', 'class', 'tilecontroller', 'monobehaviour'],\n",
       " [],\n",
       " ['serializefield'],\n",
       " ['private', 'meshfilter'],\n",
       " ['serializefield'],\n",
       " ['private', 'renderer'],\n",
       " ['private',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'transform',\n",
       "  'new',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'transform'],\n",
       " ['public',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'float',\n",
       "  'maxscales',\n",
       "  'new',\n",
       "  'dictionary',\n",
       "  'string',\n",
       "  'float'],\n",
       " [],\n",
       " ['public', 'animationcurve', 'resourcecurve'],\n",
       " [],\n",
       " ['public', 'void', 'somefunction', 'resource'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['iferror',\n",
       "  'if',\n",
       "  'or',\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  'search',\n",
       "  'found',\n",
       "  'nfound'],\n",
       " [],\n",
       " ['sub'],\n",
       " [],\n",
       " ['dim', 'strsearch', 'as', 'string'],\n",
       " ['dim', 'arysearch', 'as', 'variant'],\n",
       " ['dim', 'searchrng', 'as', 'range'],\n",
       " ['dim', 'cel', 'as', 'range'],\n",
       " ['dim', 'as', 'long', 'ii', 'as', 'long'],\n",
       " [],\n",
       " [],\n",
       " ['set', 'searchrng', 'application', 'selection'],\n",
       " ['strsearch',\n",
       "  'inputbox',\n",
       "  'please',\n",
       "  'enter',\n",
       "  'the',\n",
       "  'text',\n",
       "  'to',\n",
       "  'make',\n",
       "  'bold',\n",
       "  'as',\n",
       "  'comma',\n",
       "  'delimited',\n",
       "  'list',\n",
       "  'abc',\n",
       "  'xyz',\n",
       "  'no',\n",
       "  'spaces',\n",
       "  'bold',\n",
       "  'text'],\n",
       " ['if', 'strsearch', 'then', 'exit', 'sub'],\n",
       " ['arysearch', 'split', 'strsearch'],\n",
       " ['for', 'each', 'cel', 'in', 'searchrng'],\n",
       " [],\n",
       " ['with', 'cel'],\n",
       " [],\n",
       " ['font', 'bold', 'false'],\n",
       " ['for', 'ii', 'lbound', 'arysearch', 'to', 'ubound', 'arysearch'],\n",
       " [],\n",
       " ['instr', 'cel', 'value', 'arysearch', 'ii'],\n",
       " ['if', 'then'],\n",
       " [],\n",
       " ['characters', 'len', 'arysearch', 'ii', 'font', 'bold', 'true'],\n",
       " ['end', 'if'],\n",
       " ['next', 'ii'],\n",
       " ['end', 'with'],\n",
       " ['next', 'cel'],\n",
       " [],\n",
       " ['end', 'sub'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['documentclass', 'border', 'pt', 'standalone'],\n",
       " ['usepackage', 'makecell'],\n",
       " [],\n",
       " ['cc'],\n",
       " ['begin', 'document'],\n",
       " ['pt', 'makegapedcells'],\n",
       " ['begin', 'tabular', 'rllllll'],\n",
       " ['nline', 'hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " ['end', 'document'],\n",
       " [],\n",
       " ['documentclass', 'article'],\n",
       " [],\n",
       " ['usepackage', 'makecell', 'etoolbox'],\n",
       " [],\n",
       " ['makeatletter'],\n",
       " ['newcommand', 'nheadline'],\n",
       " ['patchcmd', 'nline', 'cmd'],\n",
       " ['num', 'search'],\n",
       " ['theadfontnum', 'replace'],\n",
       " ['success', 'failure'],\n",
       " ['theadfontnline'],\n",
       " [],\n",
       " ['makeatother'],\n",
       " [],\n",
       " ['bfseries'],\n",
       " [],\n",
       " ['begin', 'document'],\n",
       " [],\n",
       " ['begin', 'tabular'],\n",
       " ['nheadline'],\n",
       " ['nline'],\n",
       " ['hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " [],\n",
       " ['end', 'document'],\n",
       " [],\n",
       " ['documentclass', 'article'],\n",
       " [],\n",
       " ['usepackage', 'makecell', 'multido'],\n",
       " [],\n",
       " ['makeatletter'],\n",
       " [],\n",
       " ['newcommand', 'headalign', 'multicolumn'],\n",
       " ['newcommand', 'createheadline'],\n",
       " ['def', 'headline'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['multido'],\n",
       " ['edefx', 'headline', 'headline', 'headalign', 'theadfonti'],\n",
       " [],\n",
       " ['expandafter', 'gobble', 'headline'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['newcommand', 'setheadline', 'headline'],\n",
       " [],\n",
       " ['makeatother'],\n",
       " [],\n",
       " ['bfseries'],\n",
       " [],\n",
       " ['begin', 'document'],\n",
       " [],\n",
       " ['begin', 'tabular'],\n",
       " ['createheadline', 'setheadline'],\n",
       " ['nline'],\n",
       " ['hline'],\n",
       " ['like', 'to', 'center', 'the', 'numbers', 'above'],\n",
       " ['they', 'should', 'also', 'be', 'bold', 'and', 'footnotesize'],\n",
       " ['foo', 'bar', 'like', 'thead', 'baz'],\n",
       " ['end', 'tabular'],\n",
       " [],\n",
       " ['end', 'document'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['output',\n",
       "  'kali',\n",
       "  'bryant',\n",
       "  'megfogja',\n",
       "  'es',\n",
       "  'az',\n",
       "  'övére',\n",
       "  'csatolja',\n",
       "  'deasert',\n",
       "  'kaliberü',\n",
       "  'fegyvertz'],\n",
       " ['output', 'az', 'öven', 'van', 'kali', 'bryant'],\n",
       " ['output', 'boris', 'ivanokov', 'mondja', 'miért', 'veszi', 'ki'],\n",
       " ['output',\n",
       "  'kali',\n",
       "  'bryant',\n",
       "  'kivett',\n",
       "  'egy',\n",
       "  'tárgyat',\n",
       "  'jármű',\n",
       "  'desert',\n",
       "  'eagle',\n",
       "  'pisztoly'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['source', 'code', 'of', 'expert', 'system'],\n",
       " ['go'],\n",
       " ['hypothesis', 'disease'],\n",
       " ['write', 'believe', 'that', 'the', 'patient', 'have'],\n",
       " ['write', 'disease'],\n",
       " ['nl'],\n",
       " ['write', 'take', 'care'],\n",
       " ['undo'],\n",
       " [],\n",
       " ['hypothesis', 'that', 'should', 'be', 'tested'],\n",
       " ['hypothesis', 'cold', 'cold'],\n",
       " ['hypothesis', 'flu', 'flu'],\n",
       " ['hypothesis', 'typhoid', 'typhoid'],\n",
       " ['hypothesis', 'measles', 'measles'],\n",
       " ['hypothesis', 'malaria', 'malaria'],\n",
       " ['hypothesis', 'unknown', 'no', 'diagnosis'],\n",
       " [],\n",
       " ['hypothesis', 'identification', 'rules'],\n",
       " [],\n",
       " ['cold'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'runny_nose'],\n",
       " ['verify', 'sneezing'],\n",
       " ['verify', 'sore_throat'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tylenol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'panadol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'nasal', 'spray'],\n",
       " ['nl'],\n",
       " ['write', 'please', 'weare', 'warm', 'cloths', 'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['flu'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'chills'],\n",
       " ['verify', 'body_ache'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tamiflu', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'panadol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'zanamivir', 'tab'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'take',\n",
       "  'warm',\n",
       "  'bath',\n",
       "  'and',\n",
       "  'do',\n",
       "  'salt',\n",
       "  'gargling',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['typhoid'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'abdominal_pain'],\n",
       " ['verify', 'poor_appetite'],\n",
       " ['verify', 'fever'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'chloramphenicol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'amoxicillin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'ciprofloxacin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'azithromycin', 'tab'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'do',\n",
       "  'complete',\n",
       "  'bed',\n",
       "  'rest',\n",
       "  'and',\n",
       "  'take',\n",
       "  'soft',\n",
       "  'diet',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['measles'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'runny_nose'],\n",
       " ['verify', 'rash'],\n",
       " ['verify', 'conjunctivitis'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'tylenol', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'aleve', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'advil', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'vitamin'],\n",
       " ['nl'],\n",
       " ['write', 'please', 'get', 'rest', 'and', 'use', 'more', 'liquid', 'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['malaria'],\n",
       " ['verify', 'fever'],\n",
       " ['verify', 'sweating'],\n",
       " ['verify', 'headache'],\n",
       " ['verify', 'nausea'],\n",
       " ['verify', 'vomiting'],\n",
       " ['verify', 'diarrhea'],\n",
       " ['write', 'advices', 'and', 'sugestions'],\n",
       " ['nl'],\n",
       " ['write', 'aralen', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'qualaquin', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'plaquenil', 'tab'],\n",
       " ['nl'],\n",
       " ['write', 'mefloquine'],\n",
       " ['nl'],\n",
       " ['write',\n",
       "  'please',\n",
       "  'do',\n",
       "  'not',\n",
       "  'sleep',\n",
       "  'in',\n",
       "  'open',\n",
       "  'air',\n",
       "  'and',\n",
       "  'cover',\n",
       "  'your',\n",
       "  'full',\n",
       "  'skin',\n",
       "  'because'],\n",
       " ['nl'],\n",
       " [],\n",
       " ['how', 'to', 'ask', 'questions'],\n",
       " ['ask', 'question'],\n",
       " ['write', 'does', 'the', 'patient', 'have', 'following', 'symptom'],\n",
       " ['write', 'question'],\n",
       " ['write'],\n",
       " ['read', 'response'],\n",
       " ['nl'],\n",
       " ['response', 'yes', 'response'],\n",
       " [],\n",
       " ['assert', 'yes', 'question'],\n",
       " ['assert', 'no', 'question', 'fail'],\n",
       " [],\n",
       " ['dynamic', 'yes', 'no'],\n",
       " ['how', 'to', 'verify', 'something'],\n",
       " ['verify'],\n",
       " ['yes'],\n",
       " [],\n",
       " ['true'],\n",
       " ['no'],\n",
       " [],\n",
       " ['fail'],\n",
       " ['ask'],\n",
       " ['undo', 'all', 'yes', 'no', 'assertions'],\n",
       " ['undo', 'retract', 'yes', 'fail'],\n",
       " ['undo', 'retract', 'no', 'fail'],\n",
       " ['undo'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['class', 'myclass', 'ienumerable', 'int'],\n",
       " [],\n",
       " ['public', 'ienumerator', 'int', 'getenumerator'],\n",
       " [],\n",
       " ['for', 'int'],\n",
       " [],\n",
       " ['yield', 'return'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ienumerator', 'ienumerable', 'getenumerator'],\n",
       " [],\n",
       " ['return', 'ienumerable', 'this', 'getenumerator', 'всё', 'хорошо'],\n",
       " ['return', 'ienumerable', 'this', 'getenumenator', 'error'],\n",
       " [],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['portability', 'of', 'wild', 'pathname'],\n",
       " [],\n",
       " ['on',\n",
       "  'most',\n",
       "  'cl',\n",
       "  'implementations',\n",
       "  'cl',\n",
       "  'parse',\n",
       "  'namestring',\n",
       "  'or',\n",
       "  'interprets',\n",
       "  'unix',\n",
       "  'like',\n",
       "  'pathname',\n",
       "  'including',\n",
       "  'wildcard',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'qux',\n",
       "  'lisp',\n",
       "  'in',\n",
       "  'common',\n",
       "  'way',\n",
       "  'however',\n",
       "  'there',\n",
       "  'are',\n",
       "  'minor',\n",
       "  'differences',\n",
       "  'in',\n",
       "  'behaviour',\n",
       "  'and',\n",
       "  'facility',\n",
       "  'below',\n",
       "  'is',\n",
       "  'table',\n",
       "  'summarizing',\n",
       "  'the',\n",
       "  'points'],\n",
       " [],\n",
       " ['as', 'one', 'directory'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'baz', 'foo', 'baz'],\n",
       " [],\n",
       " ['as', 'zero', 'or', 'more', 'directories'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'baz', 'qux', 'foo', 'qux'],\n",
       " ['pathname', 'match', 'foo', 'qux', 'foo', 'qux'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'baz',\n",
       "  'qux',\n",
       "  'qux',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['as', 'file', 'name', 'or', 'file', 'type'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'lisp', 'foo', 'nil'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo'],\n",
       " ['pathname',\n",
       "  'name',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild',\n",
       "  'wild'],\n",
       " ['pathname',\n",
       "  'type',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'lisp', 'foo', 'bar'],\n",
       " ['pathname', 'match', 'foo', 'lisp', 'foo'],\n",
       " ['pathname', 'name', 'foo', 'bar', 'obj', 'sup', 'footnote', 'sup', 'nil'],\n",
       " ['pathname',\n",
       "  'type',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'nil',\n",
       "  'wild',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'wild'],\n",
       " [],\n",
       " ['name',\n",
       "  'footnote',\n",
       "  'sbcl',\n",
       "  'provides',\n",
       "  'class',\n",
       "  'sb',\n",
       "  'impl',\n",
       "  'pattern',\n",
       "  'for',\n",
       "  'this',\n",
       "  'purpose',\n",
       "  'which',\n",
       "  'is',\n",
       "  'here',\n",
       "  'virtually',\n",
       "  'equivalent',\n",
       "  'to'],\n",
       " [],\n",
       " ['as', 'part', 'of', 'directory', 'name'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'foo', 'bar', 'nil'],\n",
       " ['pathname', 'match', 'footprint', 'bar', 'foo', 'bar'],\n",
       " [],\n",
       " ['as', 'part', 'of', 'file', 'name', 'or', 'file', 'type'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'bar', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'test', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'js', 'foo', 'bar', 'js'],\n",
       " ['pathname', 'match', 'foo', 'bar', 'mjs', 'foo', 'bar', 'js'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'test',\n",
       "  'js',\n",
       "  'foo',\n",
       "  'bar',\n",
       "  'js',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['wildcard'],\n",
       " ['sbcl', 'ccl', 'clisp', 'abcl', 'ecl', 'acl', 'lw'],\n",
       " [],\n",
       " ['pathname', 'match', 'foo', 'baz', 'foo', 'baz', 'nil', 'nil', 'nil'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " ['pathname',\n",
       "  'match',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'foo',\n",
       "  'baz',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil',\n",
       "  'nil'],\n",
       " [],\n",
       " ['the', 'version', 'of', 'each', 'implementation', 'is', 'as', 'follows'],\n",
       " [],\n",
       " ['sbcl', 'sbcl', 'win'],\n",
       " ['clozure', 'cl', 'ccl', 'win'],\n",
       " ['clisp', 'clisp', 'win'],\n",
       " ['abcl', 'abcl', 'fasl', 'win'],\n",
       " ['ecl', 'ecl', 'cb', 'win'],\n",
       " ['allegro', 'cl', 'acl', 'win'],\n",
       " ['lispworks', 'lwpe', 'win'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['parallel', 'for', 'loop'],\n",
       " ['int',\n",
       "  'recordcount',\n",
       "  'lhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'rhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'rhs',\n",
       "  'listdata',\n",
       "  'count',\n",
       "  'lhs',\n",
       "  'listdata',\n",
       "  'count'],\n",
       " [],\n",
       " ['list', 'double', 'listresult', 'new', 'list', 'double', 'recordcount'],\n",
       " ['var', 'partitioner', 'create', 'recordcount'],\n",
       " [],\n",
       " ['parallel', 'foreach', 'range'],\n",
       " [],\n",
       " ['for', 'int', 'index', 'range', 'item', 'index', 'range', 'item', 'index'],\n",
       " [],\n",
       " ['double', 'result', 'lhs', 'listdata', 'index', 'rhs', 'listdata', 'index'],\n",
       " ['listresult', 'add', 'result'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ienumerable',\n",
       "  'double',\n",
       "  'lhs',\n",
       "  'rhs',\n",
       "  'assume',\n",
       "  'these',\n",
       "  'are',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'your',\n",
       "  'numbers'],\n",
       " ['double',\n",
       "  'result',\n",
       "  'system',\n",
       "  'linq',\n",
       "  'enumerable',\n",
       "  'zip',\n",
       "  'lhs',\n",
       "  'rhs',\n",
       "  'asparallel',\n",
       "  'toarray'],\n",
       " [],\n",
       " ['var', 'listresult', 'lhs', 'asparallel'],\n",
       " ['zip', 'rhs', 'asparallel'],\n",
       " ['tolist'],\n",
       " [],\n",
       " ['listresult', 'index', 'result'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['color', 'ffff', 'hello', 'guys'],\n",
       " ['have',\n",
       "  'an',\n",
       "  'easy',\n",
       "  'autopilot',\n",
       "  'method',\n",
       "  'which',\n",
       "  'will',\n",
       "  'for',\n",
       "  'sure',\n",
       "  'bring',\n",
       "  'you',\n",
       "  'some',\n",
       "  'big',\n",
       "  'money',\n",
       "  'and',\n",
       "  'even',\n",
       "  'more',\n",
       "  'than',\n",
       "  'per',\n",
       "  'day',\n",
       "  'if',\n",
       "  'done',\n",
       "  'right',\n",
       "  'color'],\n",
       " [],\n",
       " ['center',\n",
       "  'img',\n",
       "  'https',\n",
       "  'ibb',\n",
       "  'co',\n",
       "  'rscr',\n",
       "  'screenshot',\n",
       "  'jpg',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'why',\n",
       "  'is',\n",
       "  'this',\n",
       "  'method',\n",
       "  'so',\n",
       "  'special',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'it',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'you',\n",
       "  'some',\n",
       "  'huge',\n",
       "  'money',\n",
       "  'on',\n",
       "  'autopilot',\n",
       "  'after',\n",
       "  'some',\n",
       "  'time',\n",
       "  'and',\n",
       "  'you',\n",
       "  'can',\n",
       "  'stay',\n",
       "  'lazy',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'does',\n",
       "  'this',\n",
       "  'work',\n",
       "  'worldwide',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'yup',\n",
       "  'this',\n",
       "  'can',\n",
       "  'work',\n",
       "  'anywhere',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'even',\n",
       "  'if',\n",
       "  'you',\n",
       "  're',\n",
       "  'from',\n",
       "  'another',\n",
       "  'country',\n",
       "  'color',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'how',\n",
       "  'can',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'you',\n",
       "  'are',\n",
       "  'able',\n",
       "  'to',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'in',\n",
       "  'btc',\n",
       "  'or',\n",
       "  'paypal',\n",
       "  'color'],\n",
       " [],\n",
       " ['color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'is',\n",
       "  'this',\n",
       "  'method',\n",
       "  'legal',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'legal',\n",
       "  'and',\n",
       "  'legit',\n",
       "  'it',\n",
       "  'whitehat',\n",
       "  'this',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'kind',\n",
       "  'method',\n",
       "  'color',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center', 'size', 'size', 'size', 'size', 'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'do',\n",
       "  'need',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'money',\n",
       "  'color'],\n",
       " ['size',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'no',\n",
       "  'no',\n",
       "  'and',\n",
       "  'no',\n",
       "  'color',\n",
       "  'size',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'size',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ff',\n",
       "  'size',\n",
       "  'does',\n",
       "  'this',\n",
       "  'require',\n",
       "  'hard',\n",
       "  'work',\n",
       "  'or',\n",
       "  'do',\n",
       "  'need',\n",
       "  'any',\n",
       "  'special',\n",
       "  'skills',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center',\n",
       "  'color',\n",
       "  'ffff',\n",
       "  'size',\n",
       "  'it',\n",
       "  'only',\n",
       "  'takes',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'your',\n",
       "  'time',\n",
       "  'to',\n",
       "  'set',\n",
       "  'up',\n",
       "  'this',\n",
       "  'autopilot',\n",
       "  'method',\n",
       "  'after',\n",
       "  'that',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'fully',\n",
       "  'passive',\n",
       "  'and',\n",
       "  'automatic',\n",
       "  'and',\n",
       "  'your',\n",
       "  'only',\n",
       "  'job',\n",
       "  'from',\n",
       "  'that',\n",
       "  'moment',\n",
       "  'is',\n",
       "  'to',\n",
       "  'regularly',\n",
       "  'collect',\n",
       "  'your',\n",
       "  'earnings',\n",
       "  'size',\n",
       "  'color',\n",
       "  'center'],\n",
       " ['center', 'size', 'size', 'size', 'size', 'center'],\n",
       " ['center', 'color', 'ffffff', 'size', 'download', 'size', 'color', 'center'],\n",
       " ['center',\n",
       "  'hide',\n",
       "  'url',\n",
       "  'https',\n",
       "  'finndev',\n",
       "  'net',\n",
       "  'hsd',\n",
       "  'obm',\n",
       "  'pdf',\n",
       "  'https',\n",
       "  'finndev',\n",
       "  'net',\n",
       "  'hsd',\n",
       "  'obm',\n",
       "  'pdf',\n",
       "  'url'],\n",
       " ['no',\n",
       "  'virus',\n",
       "  'https',\n",
       "  'www',\n",
       "  'virustotal',\n",
       "  'com',\n",
       "  'file',\n",
       "  'fb',\n",
       "  'be',\n",
       "  'bbf',\n",
       "  'cbfb',\n",
       "  'de',\n",
       "  'dc',\n",
       "  'ec',\n",
       "  'ad',\n",
       "  'dbf',\n",
       "  'detection',\n",
       "  'hide',\n",
       "  'center'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['using', 'system', 'drawing'],\n",
       " ['using', 'system', 'drawing', 'text'],\n",
       " ['using', 'system', 'linq'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['summary',\n",
       "  'check',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'arial',\n",
       "  'regular',\n",
       "  'system',\n",
       "  'font',\n",
       "  'is',\n",
       "  'installed',\n",
       "  'summary'],\n",
       " ['public', 'static', 'bool'],\n",
       " [],\n",
       " ['get'],\n",
       " [],\n",
       " ['bool', 'result'],\n",
       " ['using', 'new'],\n",
       " ['fontfamily', 'fontfamilies', 'families'],\n",
       " ['fontfamily', 'ff', 'fontfamilies', 'firstordefault', 'name', 'arial'],\n",
       " ['result', 'ff', 'null', 'ff', 'fontstyle', 'regular'],\n",
       " [],\n",
       " ['return', 'result'],\n",
       " [],\n",
       " [],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'hindi',\n",
       "  'free',\n",
       "  'download',\n",
       "  'gp'],\n",
       " ['http', 'urllie', 'com', 'mncg'],\n",
       " ['copy', 'paste', 'link'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['xnxx',\n",
       "  'com',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'search',\n",
       "  'free',\n",
       "  'sex',\n",
       "  'threesome',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'sexy',\n",
       "  'ladies',\n",
       "  'arranged',\n",
       "  'marriage',\n",
       "  'dressing',\n",
       "  'taylor',\n",
       "  'bra',\n",
       "  'salesman',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'shop',\n",
       "  'tailor',\n",
       "  'hindi',\n",
       "  'full',\n",
       "  'download',\n",
       "  'oldd',\n",
       "  'iss',\n",
       "  'goldd',\n",
       "  'hindi',\n",
       "  'dubbed',\n",
       "  'movie',\n",
       "  'gp',\n",
       "  'free',\n",
       "  'apaharan',\n",
       "  'full',\n",
       "  'hd',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'kannada',\n",
       "  'movie',\n",
       "  'my',\n",
       "  'wife',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'hindi'],\n",
       " [],\n",
       " ['trending',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'and',\n",
       "  'shows',\n",
       "  'sacred',\n",
       "  'games',\n",
       "  'sanju',\n",
       "  'race',\n",
       "  'it',\n",
       "  'an',\n",
       "  'interesting',\n",
       "  'movie',\n",
       "  'no',\n",
       "  'doubt',\n",
       "  'our',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hero',\n",
       "  'is',\n",
       "  'mehboob',\n",
       "  'start',\n",
       "  'your',\n",
       "  'free',\n",
       "  'trial',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'online',\n",
       "  'free',\n",
       "  'download',\n",
       "  'fashion',\n",
       "  'quality',\n",
       "  'movie',\n",
       "  'mobile',\n",
       "  'mp',\n",
       "  'gp',\n",
       "  'mkv',\n",
       "  'free',\n",
       "  'download',\n",
       "  'hindi',\n",
       "  'dubbed',\n",
       "  'full',\n",
       "  'movie'],\n",
       " [],\n",
       " ['flv',\n",
       "  'gp',\n",
       "  'wav',\n",
       "  'formats',\n",
       "  'free',\n",
       "  'download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'mp',\n",
       "  'hd',\n",
       "  'this',\n",
       "  'video',\n",
       "  'and',\n",
       "  'mp',\n",
       "  'song',\n",
       "  'of',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'telugu',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'of',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hindi',\n",
       "  'short',\n",
       "  'film',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'raju',\n",
       "  'gari',\n",
       "  'gadhi',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'telugu',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'thiruttuvcd'],\n",
       " [],\n",
       " ['download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'rajpal',\n",
       "  'yadav',\n",
       "  'videos',\n",
       "  'using',\n",
       "  'mp',\n",
       "  'hd',\n",
       "  'webm',\n",
       "  'mkv',\n",
       "  'flv',\n",
       "  'gp',\n",
       "  'wav',\n",
       "  'formats',\n",
       "  'free',\n",
       "  'ankur',\n",
       "  'arora',\n",
       "  'murder',\n",
       "  'case',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'hindi',\n",
       "  'movies',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'ajay',\n",
       "  'devgan',\n",
       "  'full',\n",
       "  'movies',\n",
       "  'bollywood',\n",
       "  'full',\n",
       "  'movies'],\n",
       " [],\n",
       " ['tags',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'songs',\n",
       "  'video',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'bollywood',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'gp',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'video',\n",
       "  'download',\n",
       "  'mp',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'hindi',\n",
       "  'movie',\n",
       "  'songs',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'in',\n",
       "  'hindi',\n",
       "  'avi',\n",
       "  'movie',\n",
       "  'tamil',\n",
       "  'avi',\n",
       "  'telugu',\n",
       "  'gp',\n",
       "  'dowanload',\n",
       "  'fashion',\n",
       "  'designer',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'hdrip',\n",
       "  'telugu',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'watch',\n",
       "  'download',\n",
       "  'ladies',\n",
       "  'tailor',\n",
       "  'dvd',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'full',\n",
       "  'hd',\n",
       "  'movie',\n",
       "  'download',\n",
       "  'in',\n",
       "  'gp',\n",
       "  'free',\n",
       "  'hd',\n",
       "  'kya',\n",
       "  'garam',\n",
       "  'hai',\n",
       "  'hum',\n",
       "  'full',\n",
       "  'movie',\n",
       "  'free',\n",
       "  'download',\n",
       "  'in',\n",
       "  'hindi'],\n",
       " ['GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF', 'GXO_EOF'],\n",
       " ['kwerulantów'],\n",
       " ['kwerulanty'],\n",
       " ['kwerulencja'],\n",
       " ['kwerulencjach'],\n",
       " ['kwerulencjami'],\n",
       " ['kwerulencją'],\n",
       " ['kwerulencje'],\n",
       " ['kwerulencję'],\n",
       " ['kwerulencji'],\n",
       " ['kwerulencjo'],\n",
       " ['kwerulencjom'],\n",
       " ['kwerulencyj'],\n",
       " ['kwest'],\n",
       " ['kwesta'],\n",
       " ['kwestach'],\n",
       " ['kwestami'],\n",
       " ['kwestarce'],\n",
       " ['kwestarek'],\n",
       " ['kwestarka'],\n",
       " ['kwestarkach'],\n",
       " ['kwestarkami'],\n",
       " ['kwestarką'],\n",
       " ['kwestarkę'],\n",
       " ['kwestarki'],\n",
       " ['kwestarko'],\n",
       " ['kwestarkom'],\n",
       " ['kwestarscy'],\n",
       " ['kwestarska'],\n",
       " ['kwestarską'],\n",
       " ['kwestarski'],\n",
       " ['kwestarskich'],\n",
       " ['kwestarskie'],\n",
       " ['kwestarskiego'],\n",
       " ['kwestarskiej'],\n",
       " ['kwestarskiemu'],\n",
       " ['kwestarskim'],\n",
       " ['kwestarskimi'],\n",
       " ['kwestarsko'],\n",
       " ['kwestarskości'],\n",
       " ['kwestarskością'],\n",
       " ['kwestarskościom'],\n",
       " ['kwestarskość'],\n",
       " ['kwestarsku'],\n",
       " ['kwestarz'],\n",
       " ['kwestarza'],\n",
       " ['kwestarzach'],\n",
       " ['kwestarzami'],\n",
       " ['kwestarze'],\n",
       " ['kwestarzem'],\n",
       " ['kwestarzom'],\n",
       " ['kwestarzowi'],\n",
       " ['kwestarzów'],\n",
       " ['kwestarzu'],\n",
       " ['kwestarzy'],\n",
       " ['kwestą'],\n",
       " ['kwestę'],\n",
       " ['kwestia'],\n",
       " ['kwestiach'],\n",
       " ['kwestiami'],\n",
       " ['kwestią'],\n",
       " ['kwestie'],\n",
       " ['kwestię'],\n",
       " ['kwestii'],\n",
       " ['kwestio'],\n",
       " ['kwestiom'],\n",
       " ['kwestionariusz'],\n",
       " ['kwestionariusza'],\n",
       " ['kwestionariusze'],\n",
       " ['kwestionariuszu'],\n",
       " ['kwestionariuszy'],\n",
       " ['kwestionować'],\n",
       " ['kwestionowali'],\n",
       " ['kwestionowaliby'],\n",
       " ['kwestionowalna'],\n",
       " ['kwestionowalną'],\n",
       " ['kwestionowalne'],\n",
       " ['kwestionowalnej'],\n",
       " ['kwestionowalni'],\n",
       " ['kwestionowalny'],\n",
       " ['kwestionowalnym'],\n",
       " ['kwestionował'],\n",
       " ['kwestionowała'],\n",
       " ['kwestionowałaby'],\n",
       " ['kwestionowałam'],\n",
       " ['kwestionowałaś'],\n",
       " ['kwestionowałby'],\n",
       " ['kwestionowałbym'],\n",
       " ['kwestionowałbyś'],\n",
       " ['kwestionowałem'],\n",
       " ['kwestionowałeś'],\n",
       " ['kwestionowało'],\n",
       " ['kwestionowałoby'],\n",
       " ['kwestionowały'],\n",
       " ['kwestionowałyby'],\n",
       " ['kwestionowana'],\n",
       " ['kwestionowaną'],\n",
       " ['kwestionowane'],\n",
       " ['kwestionowanego'],\n",
       " ['kwestionowanej'],\n",
       " ['kwestionowanemu'],\n",
       " ['kwestionowani'],\n",
       " ['kwestionowania'],\n",
       " ['kwestionowanie'],\n",
       " ['kwestionowaniem'],\n",
       " ['kwestionowaniom'],\n",
       " ['kwestionowaniu'],\n",
       " ['kwestionowano'],\n",
       " ['kwestionowany'],\n",
       " ['kwestionowanych'],\n",
       " ['kwestionowanym'],\n",
       " ['kwestionowanymi'],\n",
       " ['kwestionowań'],\n",
       " ['kwestionuj'],\n",
       " ['kwestionują'],\n",
       " ['kwestionując'],\n",
       " ['kwestionująca'],\n",
       " ['kwestionującą'],\n",
       " ['kwestionujące'],\n",
       " ['kwestionującego'],\n",
       " ['kwestionującej'],\n",
       " ['kwestionującemu'],\n",
       " ['kwestionujący'],\n",
       " ['kwestionujących'],\n",
       " ['kwestionującym'],\n",
       " ['kwestionującymi'],\n",
       " ['kwestionujcie'],\n",
       " ['kwestionujcież'],\n",
       " ['kwestionuje'],\n",
       " ['kwestionujecie'],\n",
       " ['kwestionujemy'],\n",
       " ['kwestionujesz'],\n",
       " ['kwestionuję'],\n",
       " ['kwestionujmy'],\n",
       " ['kwestionujmyż'],\n",
       " ['kwestionujże'],\n",
       " ['kwesto'],\n",
       " ['kwestom'],\n",
       " ['kwestor'],\n",
       " ['kwestora'],\n",
       " ['kwestorach'],\n",
       " ['kwestorami'],\n",
       " ['kwestorce'],\n",
       " ['kwestorek'],\n",
       " ['kwestorem'],\n",
       " ['kwestorka'],\n",
       " ['kwestorkach'],\n",
       " ['kwestorkami'],\n",
       " ['kwestorką'],\n",
       " ['kwestorkę'],\n",
       " ['kwestorki'],\n",
       " ['kwestorko'],\n",
       " ['kwestorkom'],\n",
       " ['kwestorom'],\n",
       " ['kwestorowi'],\n",
       " ['kwestorów'],\n",
       " ['kwestorscy'],\n",
       " ['kwestorska'],\n",
       " ['kwestorską'],\n",
       " ['kwestorski'],\n",
       " ['kwestorskich'],\n",
       " ['kwestorskie'],\n",
       " ['kwestorskiego'],\n",
       " ['kwestorskiej'],\n",
       " ['kwestorskiemu'],\n",
       " ['kwestorskim'],\n",
       " ['kwestorskimi'],\n",
       " ['kwestorsko'],\n",
       " ['kwestorskości'],\n",
       " ['kwestorskością'],\n",
       " ['kwestorskościom'],\n",
       " ['kwestorskość'],\n",
       " ['kwestorsku'],\n",
       " ['kwestory'],\n",
       " ['kwestorze'],\n",
       " ['kwestorzy'],\n",
       " ['kwestować'],\n",
       " ['kwestowali'],\n",
       " ['kwestowaliby'],\n",
       " ['kwestowalibyśmy'],\n",
       " ['kwestowaliście'],\n",
       " ['kwestowaliśmy'],\n",
       " ['kwestował'],\n",
       " ['kwestowała'],\n",
       " ['kwestowałaby'],\n",
       " ['kwestowałabym'],\n",
       " ['kwestowałabyś'],\n",
       " ['kwestowałam'],\n",
       " ['kwestowałaś'],\n",
       " ['kwestowałby'],\n",
       " ['kwestowałbym'],\n",
       " ['kwestowałbyś'],\n",
       " ['kwestowałem'],\n",
       " ['kwestowałeś'],\n",
       " ['kwestowało'],\n",
       " ['kwestowałoby'],\n",
       " ['kwestowały'],\n",
       " ['kwestowałyby'],\n",
       " ['kwestowałybyśmy'],\n",
       " ['kwestowałyście'],\n",
       " ['kwestowałyśmy'],\n",
       " ['kwestowania'],\n",
       " ['kwestowaniach'],\n",
       " ['kwestowaniami'],\n",
       " ['kwestowanie'],\n",
       " ['kwestowaniem'],\n",
       " ['kwestowaniom'],\n",
       " ['kwestowaniu'],\n",
       " ['kwestowano'],\n",
       " ['kwestowań'],\n",
       " ['kwestuj'],\n",
       " ['kwestują'],\n",
       " ['kwestując'],\n",
       " ['kwestująca'],\n",
       " ['kwestującą'],\n",
       " ['kwestujące'],\n",
       " ['kwestującego'],\n",
       " ['kwestującej'],\n",
       " ['kwestującemu'],\n",
       " ['kwestujący'],\n",
       " ['kwestujących'],\n",
       " ['kwestującym'],\n",
       " ['kwestującymi'],\n",
       " ['kwestujcie'],\n",
       " ['kwestujcież'],\n",
       " ['kwestuje'],\n",
       " ['kwestujecie'],\n",
       " ['kwestujemy'],\n",
       " ['kwestujesz'],\n",
       " ['kwestuję'],\n",
       " ['kwestujmy'],\n",
       " ['kwestujmyż'],\n",
       " ['kwestujże'],\n",
       " ['kwestur'],\n",
       " ['kwestura'],\n",
       " ['kwesturach'],\n",
       " ['kwesturami'],\n",
       " ['kwesturą'],\n",
       " ['kwesturę'],\n",
       " ['kwesturo'],\n",
       " ['kwesturom'],\n",
       " ['kwestury'],\n",
       " ['kwesturze'],\n",
       " ['kwesty'],\n",
       " ['kwestyj'],\n",
       " ['kwestyjce'],\n",
       " ['kwestyjek'],\n",
       " ['kwestyjka'],\n",
       " ['kwestyjkach'],\n",
       " ['kwestyjkami'],\n",
       " ['kwestyjką'],\n",
       " ['kwestyjkę'],\n",
       " ['kwestyjki'],\n",
       " ['kwestyjko'],\n",
       " ['kwestyjkom'],\n",
       " ['kweście'],\n",
       " ['kwezal'],\n",
       " ['kwezala'],\n",
       " ['kwezalach'],\n",
       " ['kwezalami'],\n",
       " ['kwezale'],\n",
       " ['kwezalem'],\n",
       " ['kwezali'],\n",
       " ['kwezalom'],\n",
       " ['kwezalowi'],\n",
       " ['kwezalu'],\n",
       " ['kwęcz'],\n",
       " ['kwęczał'],\n",
       " ['kwęczała'],\n",
       " ['kwęczałaby'],\n",
       " ['kwęczałabym'],\n",
       " ['kwęczałabyś'],\n",
       " ['kwęczałam'],\n",
       " ['kwęczałaś'],\n",
       " ['kwęczałby'],\n",
       " ['kwęczałbym'],\n",
       " ['kwęczałbyś'],\n",
       " ['kwęczałem'],\n",
       " ['kwęczałeś'],\n",
       " ['kwęczało'],\n",
       " ['kwęczałoby'],\n",
       " ['kwęczały'],\n",
       " ['kwęczałyby'],\n",
       " ['kwęczałybyście'],\n",
       " ['kwęczałybyśmy'],\n",
       " ['kwęczałyście'],\n",
       " ['kwęczałyśmy'],\n",
       " ['kwęczano'],\n",
       " ['kwęczą'],\n",
       " ['kwęcząc'],\n",
       " ['kwęcząca'],\n",
       " ['kwęczącą'],\n",
       " ['kwęczące'],\n",
       " ['kwęczącego'],\n",
       " ['kwęczącej'],\n",
       " ['kwęczącemu'],\n",
       " ['kwęczący'],\n",
       " ['kwęczących'],\n",
       " ['kwęczącym'],\n",
       " ['kwęczącymi'],\n",
       " ['kwęczcie'],\n",
       " ['kwęczcież'],\n",
       " ['kwęczeć'],\n",
       " ['kwęczeli'],\n",
       " ['kwęczeliby'],\n",
       " ['kwęczelibyście'],\n",
       " ['kwęczelibyśmy'],\n",
       " ['kwęczeliście'],\n",
       " ['kwęczeliśmy'],\n",
       " ['kwęczenia'],\n",
       " ['kwęczeniach'],\n",
       " ...]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 23:15:52,043 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-14 23:15:52,044 : INFO : collecting all words and their counts\n",
      "2019-09-14 23:15:52,044 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-14 23:15:52,050 : INFO : PROGRESS: at sentence #10000, processed 20534 words, keeping 9048 word types\n",
      "2019-09-14 23:15:52,056 : INFO : PROGRESS: at sentence #20000, processed 49764 words, keeping 14651 word types\n",
      "2019-09-14 23:15:52,063 : INFO : PROGRESS: at sentence #30000, processed 82068 words, keeping 18892 word types\n",
      "2019-09-14 23:15:52,071 : INFO : PROGRESS: at sentence #40000, processed 120406 words, keeping 24004 word types\n",
      "2019-09-14 23:15:52,078 : INFO : PROGRESS: at sentence #50000, processed 155347 words, keeping 28335 word types\n",
      "2019-09-14 23:15:52,079 : INFO : collected 28746 word types from a corpus of 158007 raw words and 50536 sentences\n",
      "2019-09-14 23:15:52,080 : INFO : Loading a fresh vocabulary\n",
      "2019-09-14 23:15:52,114 : INFO : effective_min_count=1 retains 28746 unique words (100% of original 28746, drops 0)\n",
      "2019-09-14 23:15:52,114 : INFO : effective_min_count=1 leaves 158007 word corpus (100% of original 158007, drops 0)\n",
      "2019-09-14 23:15:52,174 : INFO : deleting the raw counts dictionary of 28746 items\n",
      "2019-09-14 23:15:52,175 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2019-09-14 23:15:52,175 : INFO : downsampling leaves estimated 148534 word corpus (94.0% of prior 158007)\n",
      "2019-09-14 23:15:52,212 : INFO : estimated required memory for 28746 words and 150 dimensions: 48868200 bytes\n",
      "2019-09-14 23:15:52,213 : INFO : resetting layer weights\n",
      "2019-09-14 23:15:52,435 : INFO : training model with 10 workers on 28746 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 23:15:52,528 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:52,530 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:52,530 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:52,531 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:52,531 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:52,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:52,531 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:52,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:52,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:52,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:52,545 : INFO : EPOCH - 1 : training on 158007 raw words (148505 effective words) took 0.1s, 1454115 effective words/s\n",
      "2019-09-14 23:15:52,631 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:52,633 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:52,634 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:52,634 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:52,637 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:52,638 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:52,639 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:52,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:52,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:52,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:52,650 : INFO : EPOCH - 2 : training on 158007 raw words (148508 effective words) took 0.1s, 1543679 effective words/s\n",
      "2019-09-14 23:15:52,732 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:52,737 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:52,738 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:52,738 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:52,740 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:52,741 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:52,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:52,747 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:52,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:52,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:52,751 : INFO : EPOCH - 3 : training on 158007 raw words (148512 effective words) took 0.1s, 1590170 effective words/s\n",
      "2019-09-14 23:15:52,838 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:52,849 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:52,851 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:52,852 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:52,852 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:52,852 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:52,855 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:52,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:52,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:52,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:52,869 : INFO : EPOCH - 4 : training on 158007 raw words (148652 effective words) took 0.1s, 1352491 effective words/s\n",
      "2019-09-14 23:15:52,950 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:52,955 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:52,956 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:52,957 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:52,958 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:52,959 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:52,961 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:52,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:52,968 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:52,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:52,969 : INFO : EPOCH - 5 : training on 158007 raw words (148497 effective words) took 0.1s, 1603738 effective words/s\n",
      "2019-09-14 23:15:52,969 : INFO : training on a 790035 raw words (742674 effective words) took 0.5s, 1390717 effective words/s\n",
      "2019-09-14 23:15:52,970 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-09-14 23:15:52,970 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-14 23:15:52,970 : INFO : training model with 10 workers on 28746 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-14 23:15:53,058 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,058 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,059 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,059 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,060 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,060 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,064 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 23:15:53,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,072 : INFO : EPOCH - 1 : training on 158007 raw words (148499 effective words) took 0.1s, 1585055 effective words/s\n",
      "2019-09-14 23:15:53,072 : WARNING : EPOCH - 1 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,158 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,166 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,167 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,168 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,168 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,169 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,172 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,180 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,184 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,184 : INFO : EPOCH - 2 : training on 158007 raw words (148551 effective words) took 0.1s, 1427883 effective words/s\n",
      "2019-09-14 23:15:53,184 : WARNING : EPOCH - 2 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,270 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,272 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,273 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,276 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,278 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,279 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,279 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,291 : INFO : EPOCH - 3 : training on 158007 raw words (148490 effective words) took 0.1s, 1499490 effective words/s\n",
      "2019-09-14 23:15:53,291 : WARNING : EPOCH - 3 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,380 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,381 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,382 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,385 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,386 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,387 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,389 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,396 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,396 : INFO : EPOCH - 4 : training on 158007 raw words (148406 effective words) took 0.1s, 1530989 effective words/s\n",
      "2019-09-14 23:15:53,396 : WARNING : EPOCH - 4 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,482 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,483 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,484 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,485 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,486 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,487 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,490 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,497 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,497 : INFO : EPOCH - 5 : training on 158007 raw words (148571 effective words) took 0.1s, 1595452 effective words/s\n",
      "2019-09-14 23:15:53,497 : WARNING : EPOCH - 5 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,579 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,584 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,585 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,585 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,589 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,593 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,599 : INFO : EPOCH - 6 : training on 158007 raw words (148608 effective words) took 0.1s, 1578506 effective words/s\n",
      "2019-09-14 23:15:53,600 : WARNING : EPOCH - 6 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,686 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,690 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,691 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,691 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,692 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,692 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,699 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,704 : INFO : EPOCH - 7 : training on 158007 raw words (148592 effective words) took 0.1s, 1538174 effective words/s\n",
      "2019-09-14 23:15:53,705 : WARNING : EPOCH - 7 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,791 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,796 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,797 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,797 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,799 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,800 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,806 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,808 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 23:15:53,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,810 : INFO : EPOCH - 8 : training on 158007 raw words (148569 effective words) took 0.1s, 1521552 effective words/s\n",
      "2019-09-14 23:15:53,810 : WARNING : EPOCH - 8 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:53,897 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:53,900 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:53,901 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:53,901 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:53,902 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:53,902 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:53,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:53,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:53,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:53,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:53,916 : INFO : EPOCH - 9 : training on 158007 raw words (148589 effective words) took 0.1s, 1505653 effective words/s\n",
      "2019-09-14 23:15:53,917 : WARNING : EPOCH - 9 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:54,000 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-14 23:15:54,008 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-14 23:15:54,008 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-14 23:15:54,009 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-14 23:15:54,009 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-14 23:15:54,011 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-14 23:15:54,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-14 23:15:54,017 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-14 23:15:54,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-14 23:15:54,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-14 23:15:54,026 : INFO : EPOCH - 10 : training on 158007 raw words (148614 effective words) took 0.1s, 1469496 effective words/s\n",
      "2019-09-14 23:15:54,026 : WARNING : EPOCH - 10 : supplied example count (50536) did not equal expected count (766508)\n",
      "2019-09-14 23:15:54,026 : INFO : training on a 1580070 raw words (1485489 effective words) took 1.1s, 1407262 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1485489, 1580070)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_token = gensim.models.Word2Vec (documents2, size=150, window=5, min_count=1, workers=10)\n",
    "model_token.train(documents2,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_creator(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        word_list=[]\n",
    "        vec_list=[]\n",
    "        average_vec=0\n",
    "        #sum_list=np.zeros(150)\n",
    "        count=0\n",
    "        for line in f: \n",
    "            word_list+=gensim.utils.simple_preprocess(line)\n",
    "        for i in word_list:\n",
    "            count+=1\n",
    "            vec_list.append(model_token.wv.get_vector(i)) #vector\n",
    "\n",
    "        q1=sum(vec_list[:math.ceil(count/4)])\n",
    "        q2=sum(vec_list[math.ceil(count/4):math.ceil(count/2)])\n",
    "        q3=sum(vec_list[math.ceil(count/2):math.ceil(3*count/4)])\n",
    "        q4=sum(vec_list[math.ceil(3*count/4):])\n",
    "        q1_234=q1-(q2+q3+q4)\n",
    "        q12_34=(q1+q2)-(q3+q4)\n",
    "        q123_4=(q1+q2+q3)-q4\n",
    "        sum_vec=sum(vec_list)\n",
    "        \n",
    "        if count!=0:\n",
    "            average_vec=sum_vec/count #average\n",
    "        else\n",
    "        #return([average_vec,q1_234, q12_34,q123_4])\n",
    "        return(np.concatenate((average_vec,q1_234, q12_34,q123_4), axis=None))\n",
    "    \n",
    "files_vectors=[]\n",
    "for file in glob.glob(\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*\"):\n",
    "    files_vectors.append(vectors_creator(file))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-726475a01029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "a[(0,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files_vectors[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.62531108e-01  1.90492898e-01 -3.15210015e-01 -9.79873538e-02\n",
      "  3.73008405e-03 -1.71369627e-01  1.65466994e-01  2.57585585e-01\n",
      "  3.13944161e-01  7.17104925e-03  1.81311816e-01 -6.44897670e-02\n",
      " -2.43299138e-02  3.82097423e-01  2.59005874e-01  3.99423718e-01\n",
      " -3.45725030e-01  1.49155617e-01 -7.36202672e-02  5.08686900e-01\n",
      "  3.85111809e-01 -1.34545401e-01  5.79842627e-01 -2.14001402e-01\n",
      "  2.47484252e-01 -1.51147619e-01  1.36945069e-01  7.02191472e-01\n",
      "  1.67360991e-01  1.96563497e-01  1.72312871e-01 -3.26711476e-01\n",
      "  2.84722894e-01  5.48251122e-02  7.18404710e-01 -3.77863079e-01\n",
      " -4.37244028e-01  9.20294896e-02 -2.53010154e-01 -1.66559041e-01\n",
      "  6.63878210e-03  2.86822021e-01  3.61746252e-01 -2.88902164e-01\n",
      " -3.80281687e-01 -2.93510228e-01 -1.71230331e-01 -3.95874768e-01\n",
      " -1.99198663e-01  1.38881326e-01 -7.24303052e-02  3.49531561e-01\n",
      " -8.76116008e-02 -1.07873209e-01 -6.21276125e-02 -2.50727594e-01\n",
      " -3.82723659e-01  3.60297352e-01 -2.34846041e-01 -4.68731582e-01\n",
      "  1.94531828e-01 -3.89202684e-02 -2.84290135e-01 -3.17321450e-01\n",
      "  5.18145978e-01 -1.79747060e-01  1.10995114e-01 -1.47473395e-01\n",
      "  6.70284629e-01  1.02726805e+00 -3.80754992e-02  9.34932902e-02\n",
      "  2.18685672e-01 -3.81717324e-01  4.51347560e-01  1.86949089e-01\n",
      " -6.84097633e-02  4.55036700e-01 -3.60851437e-02  5.10232925e-01\n",
      "  3.76944318e-02 -2.06632707e-02 -3.10939640e-01  5.40718496e-01\n",
      "  2.61110872e-01 -5.55631697e-01 -7.25685284e-02 -6.55256689e-01\n",
      " -8.27438906e-02 -1.33835450e-01  6.76043987e-01 -2.18872741e-01\n",
      "  1.25675146e-02  4.78083342e-01  3.27039152e-01 -2.18592033e-01\n",
      " -3.03055421e-02  2.89212495e-01  3.50122333e-01  2.19533399e-01\n",
      "  3.21632922e-02  1.61481321e-01  7.83483684e-02 -2.18015864e-01\n",
      " -2.22739398e-01  6.74923509e-02  1.41618624e-01 -2.17993930e-02\n",
      "  4.12145674e-01 -3.56101692e-01  5.73756576e-01 -6.81299046e-02\n",
      " -3.47875357e-01 -2.28690594e-01  8.15722421e-02  1.06570318e-01\n",
      " -1.81971043e-01  3.26107979e-01  3.74941640e-02 -1.57078445e-01\n",
      " -3.56664687e-01  2.03349411e-01  2.08748952e-01 -5.00509918e-01\n",
      "  4.91878778e-01  2.29577020e-01  3.31372112e-01 -3.49922776e-01\n",
      "  1.91200197e-01  3.08070362e-01 -2.85473347e-01 -4.40536201e-01\n",
      "  2.62571007e-01 -3.52512270e-01 -1.62151374e-03  4.37703520e-01\n",
      " -2.61685044e-01 -2.15028167e-01  1.57142669e-01  4.18349683e-01\n",
      "  5.15799582e-01 -1.16378643e-01  6.64927065e-02 -3.44525486e-01\n",
      " -1.18551582e-01 -6.50516510e-01  3.40751946e-01 -2.74576008e-01\n",
      " -6.19615555e-01  4.76014763e-02 -1.52539101e+01 -3.54412918e+01\n",
      "  4.51222153e+01  2.47449875e+01  1.10554562e+01  7.53343010e+00\n",
      " -1.72151089e+01 -3.63072357e+01 -3.92654877e+01  9.89146233e-01\n",
      " -3.66017914e+01  4.57566261e+00  1.78339691e+01 -7.05854797e+01\n",
      " -3.51860008e+01 -8.09653168e+01  3.02127953e+01 -9.57259560e+00\n",
      "  9.59638596e+00 -8.55520325e+01 -5.61728935e+01  8.07503510e+00\n",
      " -8.97254486e+01  3.34826317e+01 -3.94814682e+01  2.58562050e+01\n",
      " -3.54546623e+01 -1.24745636e+02 -9.66485596e+00 -3.13198509e+01\n",
      " -1.95041637e+01  4.06347923e+01 -4.63340836e+01  3.59619904e+00\n",
      " -1.18929985e+02  4.29576225e+01  7.33541412e+01 -1.62656956e+01\n",
      "  4.56800919e+01  2.29357014e+01  7.58469009e+00 -3.37611427e+01\n",
      " -7.88268585e+01  5.11965408e+01  4.78774719e+01  6.23196754e+01\n",
      "  4.07455292e+01  6.85594559e+01  3.72091827e+01  3.45859528e-02\n",
      "  4.46820164e+00 -5.47481270e+01  8.31732464e+00  4.48626137e+00\n",
      "  1.26467428e+01  6.15999756e+01  6.33324013e+01 -7.43825760e+01\n",
      "  3.10272274e+01  7.29785614e+01 -1.38714619e+01  5.38078690e+00\n",
      "  3.71607132e+01  5.56068420e+01 -7.00770264e+01  2.91949387e+01\n",
      " -2.39782372e+01  3.52242088e+00 -1.19059258e+02 -1.72915787e+02\n",
      " -8.51657009e+00  1.34095535e+01 -3.55503998e+01  5.09578438e+01\n",
      " -6.40131912e+01 -1.24402142e+01  3.01092453e+01 -9.34453888e+01\n",
      "  9.97645664e+00 -6.89193115e+01  3.79997683e+00 -7.88409424e+00\n",
      "  5.12532806e+01 -8.79411240e+01 -4.04184341e+01  1.02702698e+02\n",
      "  1.10849590e+01  1.07872757e+02  1.21618156e+01  2.13260307e+01\n",
      " -1.16054932e+02  2.30413628e+01  4.45811558e+00 -6.19311295e+01\n",
      " -4.10580215e+01  3.69768372e+01  1.15109253e+01 -4.98891411e+01\n",
      " -6.49109268e+01 -2.34240532e+01  1.34003592e+00 -2.67345009e+01\n",
      " -7.97913933e+00  4.81624069e+01  3.22042923e+01 -1.25899391e+01\n",
      " -3.95090065e+01 -5.80257511e+00 -7.20892029e+01  3.59320908e+01\n",
      " -9.75314331e+01  1.56887541e+01  5.42368164e+01  4.04705429e+01\n",
      "  2.42392826e+00 -3.16018620e+01  2.94875870e+01 -5.26333237e+01\n",
      " -1.23812323e+01  1.19887085e+01  6.43327789e+01 -5.05911598e+01\n",
      " -2.52873306e+01  7.73949127e+01 -9.50479736e+01 -2.27584648e+01\n",
      " -6.42600555e+01  6.13634529e+01 -2.16672421e+01 -4.64539185e+01\n",
      "  3.26205635e+01  6.64984131e+01 -3.30145035e+01  5.99863701e+01\n",
      " -1.02439651e+01 -5.18737984e+01  2.35088882e+01  3.54194565e+01\n",
      " -1.56724453e+01 -5.57906342e+01 -6.76183701e+01  2.29585762e+01\n",
      "  1.27661800e+00  4.46098824e+01  2.79537392e+01  1.13006119e+02\n",
      " -6.14430122e+01  5.85288277e+01  9.60083542e+01 -1.57304516e+01\n",
      "  9.19781494e+00 -3.31792831e+00  3.93459702e+00  7.31782722e+00\n",
      "  1.22569103e+01 -1.42386131e+01  4.76285172e+00  3.30152130e+00\n",
      "  4.68374634e+00  3.87729573e+00  2.78668976e+00 -1.76585579e+00\n",
      "  7.26329470e+00 -1.42741394e+01  4.75144196e+00 -1.53769379e+01\n",
      " -2.15319176e+01  9.50309181e+00 -6.67698002e+00 -1.79531097e+00\n",
      "  6.72264099e+00 -1.42800064e+01  3.87271118e+00  2.58055496e+00\n",
      "  1.16228485e+00 -7.15944290e+00 -7.48780632e+00 -6.42813110e+00\n",
      "  1.36946640e+01  4.34706879e+00  2.03599930e+00 -9.53797913e+00\n",
      "  6.17382050e+00  1.04627762e+01  7.60330200e+00 -2.27387314e+01\n",
      " -6.09207153e-01 -4.40576744e+00  6.35490036e+00 -1.91246033e+00\n",
      "  7.97348595e+00  1.00191727e+01 -1.02777061e+01  1.83952332e-01\n",
      " -1.09255180e+01  1.10301895e+01  1.45250015e+01  2.98919678e+00\n",
      "  8.71717834e+00  2.36092987e+01 -4.41225815e+00  4.15063858e+00\n",
      " -3.79409027e+00 -8.92107868e+00  5.56310177e+00  1.81291161e+01\n",
      "  7.43408203e-01 -1.00254898e+01 -4.09728622e+00 -1.72694397e+00\n",
      "  1.43530922e+01 -9.52999115e+00 -8.52863312e-01  6.56128693e+00\n",
      "  2.60207138e+01 -4.39220047e+00 -6.61319447e+00 -1.73350887e+01\n",
      " -2.53739929e+00 -6.55165100e+00 -1.10079346e+01  2.56179314e+01\n",
      "  5.31324005e+00 -9.41308594e+00  5.32167816e+00  1.43950539e+01\n",
      "  1.63712559e+01 -1.26670074e+01  6.10655546e+00  1.35578537e+01\n",
      "  5.16965151e+00 -7.00921392e+00 -9.59812164e-01 -4.97252655e+00\n",
      " -9.23622131e-01 -2.31269836e-01  6.50309563e+00 -2.02889252e+00\n",
      "  1.02759552e+00  3.28837395e+00 -1.14859085e+01 -1.54675674e+01\n",
      "  7.02789879e+00  1.60110016e+01  5.44587326e+00 -2.56490707e+00\n",
      "  9.11716461e+00 -5.24734116e+00  3.67539215e+00  1.02241325e+01\n",
      "  1.18367062e+01 -4.08336449e+00  7.43779564e+00  1.72424202e+01\n",
      " -1.22213326e+01 -7.05137539e+00 -1.76605511e+01 -1.18913879e+01\n",
      " -3.43376923e+00 -2.24087143e+01 -8.05491638e+00  3.50002289e+00\n",
      "  1.74857712e+00 -3.61280060e+00  1.42492867e+01 -1.10275831e+01\n",
      "  3.67646790e+00 -3.75017548e+00 -7.17571497e+00 -8.82798767e+00\n",
      "  4.92618561e+00 -4.67734528e+00  1.01320267e+01 -2.25923157e+00\n",
      " -1.57734070e+01  1.71913071e+01 -9.43424988e+00  5.83523178e+00\n",
      "  3.86222458e+00  3.69109344e+00 -1.18028488e+01 -1.58206177e+00\n",
      "  1.94187164e+00 -4.74759674e+00 -4.90036774e+00  1.65018616e+01\n",
      " -1.43350410e+01 -5.98381805e+00  1.20806770e+01  1.00564728e+01\n",
      "  9.29406738e+00  3.02111053e+00  4.93240356e+00 -8.20398331e+00\n",
      "  1.02565041e+01  8.29055786e-01 -5.11538696e+00  8.02671051e+00\n",
      " -8.61106110e+00 -2.68328476e+00  2.39914417e+01  2.82360191e+01\n",
      " -5.32283287e+01 -1.33743401e+01  7.21432972e+00 -3.25826302e+01\n",
      "  3.11855526e+01  4.19495888e+01  5.41338654e+01  1.77220654e+00\n",
      "  3.21110916e+01 -1.32397327e+01 -8.97837877e-01  5.98489418e+01\n",
      "  4.75665359e+01  6.40860748e+01 -5.90539474e+01  2.69532471e+01\n",
      " -1.71969376e+01  8.24652405e+01  6.80256958e+01 -2.84591217e+01\n",
      "  9.97144623e+01 -3.98015594e+01  4.26235428e+01 -2.32670174e+01\n",
      "  2.45879135e+01  1.25503784e+02  3.18831177e+01  3.46065292e+01\n",
      "  3.11679821e+01 -5.65631104e+01  4.56311417e+01  1.05760288e+01\n",
      "  1.19665939e+02 -6.50297012e+01 -7.61865997e+01  1.77333126e+01\n",
      " -4.26689644e+01 -2.98863487e+01  5.16005278e+00  5.35592422e+01\n",
      "  6.11879845e+01 -4.73263130e+01 -7.14810410e+01 -4.50800972e+01\n",
      " -2.52516651e+01 -6.67968597e+01 -3.40824432e+01  2.87878113e+01\n",
      " -1.48172932e+01  5.77318344e+01 -1.27857704e+01 -1.87989616e+01\n",
      " -1.19230347e+01 -4.34733124e+01 -6.29108429e+01  5.87173920e+01\n",
      " -3.67918892e+01 -7.78811111e+01  3.54854660e+01 -6.87991524e+00\n",
      " -4.67212868e+01 -5.04608231e+01  9.43926392e+01 -3.17668781e+01\n",
      "  2.07436333e+01 -2.84767799e+01  1.10591110e+02  1.71736572e+02\n",
      " -1.10141249e+01  1.92748184e+01  3.44948082e+01 -6.69418793e+01\n",
      "  7.40003052e+01  3.05367641e+01 -8.91654205e+00  7.81811066e+01\n",
      " -4.91198635e+00  8.58542786e+01  6.43820858e+00 -5.81065941e+00\n",
      " -5.49592590e+01  8.79442673e+01  4.61979141e+01 -8.97607193e+01\n",
      " -9.82124901e+00 -1.07354576e+02 -1.38586578e+01 -2.15596046e+01\n",
      "  1.15928436e+02 -4.21927719e+01  4.58077240e+00  8.53525848e+01\n",
      "  5.90435371e+01 -4.00327644e+01 -1.64566422e+00  5.00606155e+01\n",
      "  5.94022179e+01  3.90726357e+01  4.52690172e+00  2.85674248e+01\n",
      "  1.46840944e+01 -3.49522324e+01 -4.07916603e+01  1.15106888e+01\n",
      "  2.78425865e+01 -5.33905172e+00  6.50464935e+01 -6.31608810e+01\n",
      "  9.74833984e+01 -1.44195757e+01 -5.52398376e+01 -3.96889114e+01\n",
      "  1.72912140e+01  1.97891159e+01 -3.12092438e+01  4.94485245e+01\n",
      "  5.00366879e+00 -2.29883041e+01 -6.32550583e+01  3.79090271e+01\n",
      "  3.69423370e+01 -8.32539215e+01  8.59222183e+01  4.77236824e+01\n",
      "  5.52489777e+01 -6.10654678e+01  3.47528877e+01  5.22653732e+01\n",
      " -4.80422897e+01 -7.08043900e+01  4.72641068e+01 -6.16613083e+01\n",
      " -7.78302789e-01  7.89189911e+01 -4.37230377e+01 -3.81022720e+01\n",
      "  3.04259148e+01  7.32769623e+01  8.84012146e+01 -1.69546871e+01\n",
      "  9.12527084e+00 -5.74881325e+01 -1.65070457e+01 -1.10802719e+02\n",
      "  5.58379364e+01 -4.60740280e+01 -1.09012100e+02  6.39268112e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f0 = files_vectors[0]\n",
    "print(f0)\n",
    "f1 = files_vectors[1]\n",
    "f2 = files_vectors[2]\n",
    "f3 = files_vectors[3]\n",
    "X = np.array(list(zip(f0, f1)))\n",
    "#plt.scatter(f0, f1, c='black', s=7)\n",
    "plt.scatter(f0, f1, c=f2, s=5,  vmin=1, vmax=5)\n",
    "clusters = np.zeros(len(X))\n",
    "if 0:\n",
    "    for i in range(len(X)):\n",
    "        distances = dist(X[i], C)\n",
    "        cluster = np.argmin(distances)\n",
    "        clusters[i] = cluster\n",
    "    C_old = deepcopy(C)\n",
    "    # Finding the new centroids by taking the average value\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        C[i] = np.mean(points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/5bf341e4e2c4e4e0a124e1798b1b3afdb4d9db00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'matrixsize' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-8b1820da3865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#word_list+=[\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mvec_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0msuma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mleng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/miniconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/miniconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'matrixsize' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "#old\n",
    "for file in glob.glob(\"/mnt/servx1vol/Bams/genXone/20190914_1350_hackyeah/hackyeah_data_80/5bf/*\"):\n",
    "    print(file)\n",
    "    with open(file, 'rb') as f:\n",
    "        word_list=[]\n",
    "        vec_list=[]\n",
    "        average_list=[0,0,0,0,0,0]\n",
    "        \n",
    "        for line in f: \n",
    "            word_list+=gensim.utils.simple_preprocess(line)\n",
    "        #word_list+=[\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\",\"GXO_EOF\"]\n",
    "        for i in word_list:\n",
    "            vec_list.append(model.wv.get_vector(i)) #vector\n",
    "            suma=sum(model.wv.get_vector(i))\n",
    "            leng=len(model.wv.get_vector(i))\n",
    "            #print(suma)\n",
    "            #print(suma/leng)\n",
    "            #print(sum(model.wv.get_vector(i)[:math.ceil(leng/4)])/(leng/4))\n",
    "            #print(sum(model.wv.get_vector(i)[math.ceil(leng/4):math.ceil(leng/2)])/(leng/4))\n",
    "            #print(sum(model.wv.get_vector(i)[math.ceil(leng/2):math.ceil(3*leng/4)])/(leng/4))\n",
    "            #print(sum(model.wv.get_vector(i)[math.ceil(3*leng/4):])/(leng/4))\n",
    "            #print(model.wv.get_vector(i))\n",
    "            average_list = map(lambda x, y: x + y, average_list, ([suma,suma/leng, \\\n",
    "                                 sum(model.wv.get_vector(i)[:math.ceil(leng/4)])/(leng/4), \\\n",
    "                                 sum(model.wv.get_vector(i)[math.ceil(leng/4):math.ceil(leng/2)])/(leng/4), \\\n",
    "                                 sum(model.wv.get_vector(i)[math.ceil(leng/2):math.ceil(3*leng/4)])/(leng/4), \\\n",
    "                                 sum(model.wv.get_vector(i)[math.ceil(3*leng/4):])/(leng/4)]) )\n",
    "            #print(list(result)) \n",
    "    break \n",
    "print(list(average_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76181122646029453"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25355593501920781"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
